[{"content":"重新读了三体小说，利用的碎片时间，还有国庆几天假期。内容包括地球往事、黑暗森林、死神永生三部曲。也有一些博主的解读和评论。\n这部小说包含的内容涉及太深太广，这里仅复盘下自己的收获：\n人性 1.2.3部里都有大量人性的恶的部分，感觉总体人性是讲人类走向灭亡的根本原因。\n历史仅是一个循环，并不是教训 人类环境就是一个黑暗森林，个人都是猎人，所以没有善良与恶略 极端情况下，都是坏人 面壁计划 正面实力被碾压，并不是没有机会，面壁计划就是为了抓住三体的弱点，来形成的一些取巧或者弯道超车或者是 计谋，阴谋 阳谋等方式来对抗之\n不要放弃，没有一段努力是白费的。罗辑形成的威慑纪元前提里有其他面壁者的产物\n可怕的水滴 最让我燃起来的一段是水滴击穿整个舰队的那段，因为整体情节有强烈的反差感，脑补的画面也是大片的场景。\n首先是 人类的傲慢 以为能全方面压制三体，各个舰队为了荣耀几乎是全军出动，然后被团灭。 水滴本身的高端之处 材料学上高深技术，是当时人类几乎不可突破的。功效上不怕人类的激光，核聚变等武器，这是基础物理学上的碾压 动力上非常高端，能以锐角的角度做变相，速度几乎不打折，这是要突破牛顿的惯性定律了，也算是突破人类基础物理学了 还有比较强悍的软件能力：在人类舰队凌乱后，能迅速计算出各个击破的最短路径 虽然具备一身高科技，但是它本身攻击方式却是最传统的的方式：撞击（相对于激光等武器） 水滴只是一个探测器，想一想母舰会有多强大吧 这一段的描写算是第二部的高潮部分了，也被一些动漫制作者做成了短片，B 站上就有。\n宇宙社会学 这个是三体里第二部的核心，是罗辑对三体文明提出威胁的根基。最早是叶文洁提出并传授给了罗辑。\n都 tm 别玩了。\n因为水滴的存在硬刚三体肯定是不行了，就是靠这个基础，加上博弈论，加上雪地工程，摇篮系统来完成对三体社会的要挟。要么都别存在了，要么达成一些协议。\n让我们来看下宇宙社会学核心：\n生存是文明的第一要素 文明不断发展，但宇宙资源有限 还有两条辅助的延伸\n猜疑链 文明的技术爆炸 这四条构成了黑暗森林法则的基础。文明为了生存，必须隐藏自己，一旦暴露就会被消灭。\n记得之前很多产品经理推荐看本书的点就是这个。把做产品的过程比作宇宙文明的发展，产品经理就是文明的领导者。要不断提升产品的竞争力，避免被市场淘汰。\n不是科幻胜似科幻 其实三体更像是一个哲学小说，探讨了文明的生存、发展、冲突等问题。科幻只是一个载体，承载了这些思想。\n比如 文革 这个敏感话题的思考，宇宙社区学，黑暗森林法则，文明的进化等都是人类社会的隐喻。只是带上了科幻这个艺术形式的表达形式\n感叹作者知识面的宽厚 刘慈欣的知识面真的很宽厚，物理、天文学、数学、计算机、社会学、哲学等都有涉猎。能把这些知识融合在一起，编织出一个宏大的故事，实在令人佩服。\n不只是知识面，还有对人性的洞察，对人类之间的关系的理解。书中对人类的描写，既有光辉的一面，也有阴暗的一面。让人感受到人性的复杂和多样。\n能写出这样的效果，必须有切身的体验才行。想一想自己在城市里虽然接触很多人，但都是过客，能深入的核心接触的很少，很难深刻体验到这种关系，人性。\n漏洞疑惑 智子 与 思想钢印 思想钢印里，可以修改人类大脑神经元的响应。有一点现在 AI 领域里神经网络的权重参数一样。那为何智子不去修改人们的神经元？修改罗辑的神经元？\n对比上次读 第一次读，是几年前吧，那时只是朋友推荐，自己强制去读。感觉像是硬着读下去，只记得一些不完整的框架，灵魂因素都没记忆了。\n相比这次，完全是享受的过程，读的很细，参与感很强，也收获很多，此后读书时一定要再多嚼一嚼，理一理才能有收获颇丰，不浪费时间。\n","permalink":"https://tomorrowthief.github.io/posts/santi/","summary":"\u003cp\u003e重新读了三体小说，利用的碎片时间，还有国庆几天假期。内容包括地球往事、黑暗森林、死神永生三部曲。也有一些博主的解读和评论。\u003c/p\u003e\n\u003cp\u003e这部小说包含的内容涉及太深太广，这里仅复盘下自己的收获：\u003c/p\u003e","title":"《三体》读后感"},{"content":" 以下内容 95% 由 AI 生成\nSSE 协议与 Markdown 渲染：构建现代 AI 对话系统的基石\n在 ChatGPT、Claude 等 AI 对话系统中，那种逐字逐句的\u0026quot;打字机\u0026quot;效果背后，是两项看似普通却至关重要的技术：Server-Sent Events (SSE) 协议和 Markdown 渲染引擎。本文将深入剖析这两项技术的原理、实现细节，以及在 AI 时代的创新应用。\nSSE 协议 为什么选择 SSE？ WebSocket 功能强大，但对于单向的服务器推送场景，SSE 提供了更简洁的解决方案。它基于 HTTP 协议，无需额外的握手过程，天然支持断线重连，完美契合 AI 对话的流式输出需求。\nSSE 的核心优势在于其简单性：\n基于标准 HTTP，无需特殊协议升级 自动重连机制，网络容错性强 文本协议，调试友好 浏览器原生支持，无需额外库 协议解析：一行一世界 SSE 协议看似简单，实则暗藏玄机。每个事件由多行文本组成，以空行分隔：\nid: 123 event: message data: {\u0026#34;type\u0026#34;: \u0026#34;answer\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;这是\u0026#34;} data: {\u0026#34;type\u0026#34;: \u0026#34;answer\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;AI的回答\u0026#34;} id: 124 event: message data: {\u0026#34;type\u0026#34;: \u0026#34;answer\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;继续输出\u0026#34;} 关键字段解析：\ndata: 事件数据，可有多行，自动拼接 id: 事件 ID，用于断线重连时的位置恢复 event: 事件类型，默认为 \u0026ldquo;message\u0026rdquo; retry: 重连间隔，服务器可动态调整 实战：手写 SSE 客户端 现代浏览器的 EventSource API 虽易用，但灵活性不足。手动实现 SSE 客户端能让我们完全掌控数据流：\nclass SSEClient { constructor(url, options = {}) { this.url = url; this.headers = options.headers || {}; this.onMessage = options.onMessage || (() =\u0026gt; {}); this.onError = options.onError || (() =\u0026gt; {}); this.onConnect = options.onConnect || (() =\u0026gt; {}); this.buffer = \u0026#39;\u0026#39;; this.controller = null; } async connect() { try { this.controller = new AbortController(); const response = await fetch(this.url, { headers: { \u0026#39;Accept\u0026#39;: \u0026#39;text/event-stream\u0026#39;, \u0026#39;Cache-Control\u0026#39;: \u0026#39;no-cache\u0026#39;, ...this.headers }, signal: this.controller.signal }); if (!response.ok) { throw new Error(`HTTP ${response.status}`); } this.onConnect(); const reader = response.body.getReader(); const decoder = new TextDecoder(); while (true) { const { done, value } = await reader.read(); if (done) { this.onError(new Error(\u0026#39;Stream ended\u0026#39;)); break; } this.buffer += decoder.decode(value, { stream: true }); this.processBuffer(); } } catch (error) { if (error.name !== \u0026#39;AbortError\u0026#39;) { this.onError(error); } } } processBuffer() { const lines = this.buffer.split(\u0026#39;\\n\u0026#39;); this.buffer = lines.pop() || \u0026#39;\u0026#39;; let event = null; for (const line of lines) { if (line === \u0026#39;\u0026#39;) { if (event \u0026amp;\u0026amp; event.data) { this.onMessage(event); } event = null; continue; } if (!event) { event = { id: null, event: \u0026#39;message\u0026#39;, data: \u0026#39;\u0026#39;, retry: null }; } const colonIndex = line.indexOf(\u0026#39;:\u0026#39;); if (colonIndex === -1) continue; const field = line.slice(0, colonIndex); const value = line.slice(colonIndex + 1).replace(/^\\s/, \u0026#39;\u0026#39;); switch (field) { case \u0026#39;data\u0026#39;: event.data += (event.data ? \u0026#39;\\n\u0026#39; : \u0026#39;\u0026#39;) + value; break; case \u0026#39;id\u0026#39;: event.id = value; break; case \u0026#39;event\u0026#39;: event.event = value; break; case \u0026#39;retry\u0026#39;: event.retry = parseInt(value, 10); break; } } } disconnect() { if (this.controller) { this.controller.abort(); } } } // 使用示例 const client = new SSEClient(\u0026#39;/api/chat\u0026#39;, { onConnect: () =\u0026gt; console.log(\u0026#39;已连接\u0026#39;), onMessage: (event) =\u0026gt; { const data = JSON.parse(event.data); console.log(\u0026#39;收到消息:\u0026#39;, data); }, onError: (error) =\u0026gt; console.error(\u0026#39;连接错误:\u0026#39;, error) }); client.connect(); 业务协议设计：在 SSE 之上 实际应用中，我们通常在 SSE 协议之上封装业务协议。以 AI 对话为例：\n// 业务协议格式 { \u0026#34;type\u0026#34;: \u0026#34;thought\u0026#34;, // 思考过程 \u0026#34;content\u0026#34;: \u0026#34;让我分析一下...\u0026#34;, \u0026#34;node_id\u0026#34;: \u0026#34;node_123\u0026#34; } { \u0026#34;type\u0026#34;: \u0026#34;tool_call\u0026#34;, // 工具调用 \u0026#34;tool\u0026#34;: \u0026#34;search\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;...\u0026#34; } } { \u0026#34;type\u0026#34;: \u0026#34;answer\u0026#34;, // 最终回答 \u0026#34;content\u0026#34;: \u0026#34;根据分析...\u0026#34;, \u0026#34;finished\u0026#34;: true } { \u0026#34;type\u0026#34;: \u0026#34;message_end\u0026#34;, // 消息结束 \u0026#34;metadata\u0026#34;: { \u0026#34;total_tokens\u0026#34;: 150, \u0026#34;model\u0026#34;: \u0026#34;gpt-4\u0026#34; } } 这种分层设计让 SSE 专注于传输，业务逻辑保持清晰。\n错误处理与重连机制 class RobustSSEClient extends SSEClient { constructor(url, options = {}) { super(url, options); this.maxRetries = options.maxRetries || 3; this.retryDelay = options.retryDelay || 1000; this.retryCount = 0; this.lastEventId = null; } async connect() { try { // 添加最后的事件 ID if (this.lastEventId) { this.headers[\u0026#39;Last-Event-ID\u0026#39;] = this.lastEventId; } await super.connect(); this.retryCount = 0; // 重置重试计数 } catch (error) { this.handleConnectionError(error); } } handleConnectionError(error) { if (this.retryCount \u0026lt; this.maxRetries) { this.retryCount++; console.log(`连接失败，${this.retryDelay}ms 后重试 (第 ${this.retryCount} 次)`); setTimeout(() =\u0026gt; { this.connect(); }, this.retryDelay); // 指数退避 this.retryDelay = Math.min(this.retryDelay * 2, 30000); } else { this.onError(new Error(\u0026#39;最大重试次数已达上限\u0026#39;)); } } onMessage(event) { // 保存最后的事件 ID if (event.id) { this.lastEventId = event.id; } super.onMessage(event); } } markdown 渲染 解析原理：DSL 的三部曲 Markdown 渲染本质上是领域特定语言（DSL）的处理过程，遵循经典的编译原理：\n词法分析：将字符流转换为记号（Token）流 语法分析：将记号组合成语法结构 代码生成：将语法结构转换为目标格式（HTML） 流式渲染：打字机效果的核心 在 AI 对话系统中，我们需要实现增量渲染来支持流式输出：\n/** * 流式Markdown渲染器 * 支持增量解析，适用于SSE流式数据 */ class StreamingMarkdownRenderer { constructor() { this.patterns = { header: /^(#{1,6})\\s+(.+)$/gm, bold: /\\*\\*(.*?)\\*\\*/g, italic: /\\*(.*?)\\*/g, inlineCode: /`([^`]+)`/g, codeBlock: /```([\\s\\S]*?)```/g, blockquote: /^\u0026gt;\\s*(.+)$/gm, unorderedList: /^[-*+]\\s+(.+)$/gm, orderedList: /^\\d+\\.\\s+(.+)$/gm, link: /\\[([^\\]]+)\\]\\(([^)]+)\\)/g }; this.buffer = \u0026#39;\u0026#39;; this.completedHtml = \u0026#39;\u0026#39;; } processChunk(chunk) { this.buffer += chunk; // 尝试解析完整的 Markdown 块 const blocks = this.extractCompleteBlocks(this.buffer); if (blocks.complete.length \u0026gt; 0) { const html = this.render(blocks.complete.join(\u0026#39;\\n\\n\u0026#39;)); this.completedHtml += html; this.buffer = blocks.incomplete; return { html: this.completedHtml, delta: html, isComplete: false }; } return { html: this.completedHtml, delta: \u0026#39;\u0026#39;, isComplete: false }; } extractCompleteBlocks(text) { const paragraphs = text.split(\u0026#39;\\n\\n\u0026#39;); const complete = []; let incomplete = \u0026#39;\u0026#39;; for (let i = 0; i \u0026lt; paragraphs.length; i++) { const para = paragraphs[i].trim(); if (this.isCompleteElement(para)) { complete.push(para); } else if (i === paragraphs.length - 1) { incomplete = para; } else { complete.push(para); } } return { complete, incomplete }; } isCompleteElement(para) { if (/^#{1,6}\\s+/.test(para)) return true; if (para.includes(\u0026#39;```\u0026#39;)) { const matches = para.match(/```/g); return matches \u0026amp;\u0026amp; matches.length % 2 === 0; } if (/^[-*+\\d+]\\s+/.test(para)) return true; if (/^\u0026gt;\\s+/.test(para)) return true; return para.length \u0026gt; 0 \u0026amp;\u0026amp; para.length \u0026lt; 200; } render(markdown) { let html = markdown; // 处理顺序很重要 html = this.renderCodeBlocks(html); html = this.renderHeaders(html); html = this.renderBlockquotes(html); html = this.renderLists(html); html = this.renderInlineElements(html); html = this.renderParagraphs(html); return html; } renderCodeBlocks(text) { return text.replace(this.patterns.codeBlock, (match, code) =\u0026gt; { const cleanCode = code.replace(/^\\n|\\n$/g, \u0026#39;\u0026#39;); return `\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;${this.escapeHtml(cleanCode)}\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;`; }); } renderHeaders(text) { return text.replace(this.patterns.header, (match, hashes, content) =\u0026gt; { const level = hashes.length; return `\u0026lt;h${level}\u0026gt;${content.trim()}\u0026lt;/h${level}\u0026gt;`; }); } renderBlockquotes(text) { return text.replace(this.patterns.blockquote, \u0026#39;\u0026lt;blockquote\u0026gt;$1\u0026lt;/blockquote\u0026gt;\u0026#39;); } renderLists(text) { let html = text; html = html.replace(this.patterns.unorderedList, \u0026#39;\u0026lt;li\u0026gt;$1\u0026lt;/li\u0026gt;\u0026#39;); html = html.replace(this.patterns.orderedList, \u0026#39;\u0026lt;li\u0026gt;$1\u0026lt;/li\u0026gt;\u0026#39;); return this.wrapListItems(html); } wrapListItems(text) { text = text.replace(/(\u0026lt;li\u0026gt;.*\u0026lt;\\/li\u0026gt;)(?![\\s\\S]*\u0026lt;\\/ul\u0026gt;)/g, (match) =\u0026gt; !match.includes(\u0026#39;\u0026lt;ul\u0026gt;\u0026#39;) ? `\u0026lt;ul\u0026gt;${match}\u0026lt;/ul\u0026gt;` : match); text = text.replace(/(\u0026lt;li\u0026gt;.*\u0026lt;\\/li\u0026gt;)(?![\\s\\S]*\u0026lt;\\/ol\u0026gt;)/g, (match) =\u0026gt; !match.includes(\u0026#39;\u0026lt;ol\u0026gt;\u0026#39;) ? `\u0026lt;ol\u0026gt;${match}\u0026lt;/ol\u0026gt;` : match); return text; } renderInlineElements(text) { text = text.replace(this.patterns.bold, \u0026#39;\u0026lt;strong\u0026gt;$1\u0026lt;/strong\u0026gt;\u0026#39;); text = text.replace(this.patterns.italic, \u0026#39;\u0026lt;em\u0026gt;$1\u0026lt;/em\u0026gt;\u0026#39;); text = text.replace(this.patterns.inlineCode, \u0026#39;\u0026lt;code\u0026gt;$1\u0026lt;/code\u0026gt;\u0026#39;); text = text.replace(this.patterns.link, \u0026#39;\u0026lt;a href=\u0026#34;$2\u0026#34;\u0026gt;$1\u0026lt;/a\u0026gt;\u0026#39;); return text; } renderParagraphs(text) { const lines = text.split(\u0026#39;\\n\u0026#39;); let result = \u0026#39;\u0026#39;; let inParagraph = false; for (let line of lines) { line = line.trim(); if (!line || this.isHtmlElement(line)) { if (inParagraph) { result += \u0026#39;\u0026lt;/p\u0026gt;\u0026#39;; inParagraph = false; } result += line + \u0026#39;\\n\u0026#39;; continue; } if (!inParagraph) { result += \u0026#39;\u0026lt;p\u0026gt;\u0026#39;; inParagraph = true; } result += line; } if (inParagraph) { result += \u0026#39;\u0026lt;/p\u0026gt;\u0026#39;; } return result; } isHtmlElement(line) { return /^(\u0026lt;h[1-6]\u0026gt;|\u0026lt;pre\u0026gt;|\u0026lt;blockquote\u0026gt;|\u0026lt;ul\u0026gt;|\u0026lt;ol\u0026gt;|\u0026lt;li\u0026gt;)/.test(line); } escapeHtml(text) { const div = document.createElement(\u0026#39;div\u0026#39;); div.textContent = text; return div.innerHTML; } } 性能优化：节流渲染 class ThrottledRenderer { constructor(renderer, fps = 30) { this.renderer = renderer; this.frameInterval = 1000 / fps; this.lastFrame = 0; this.pendingRenders = []; } scheduleRender(content) { this.pendingRenders.push(content); this.processRenders(); } processRenders() { const now = performance.now(); if (now - this.lastFrame \u0026gt;= this.frameInterval) { if (this.pendingRenders.length \u0026gt; 0) { const combined = this.pendingRenders.join(\u0026#39;\u0026#39;); this.pendingRenders = []; this.renderer.processChunk(combined); this.lastFrame = now; } } if (this.pendingRenders.length \u0026gt; 0) { requestAnimationFrame(() =\u0026gt; this.processRenders()); } } } markdown-it 组件 markdown-it 是目前最流行的 JavaScript Markdown 解析器之一，它基于 CommonMark 规范实现，具有高性能和良好的扩展性。\n核心原理 markdown-it 采用两阶段解析架构：\n词法分析阶段：将输入文本分解为 Token 流 渲染阶段：将 Token 转换为 HTML const md = require(\u0026#39;markdown-it\u0026#39;)(); const tokens = md.parse(\u0026#39;# Hello\\n\\n**World**\u0026#39;); // 生成 Token 流 const html = md.renderer.render(tokens); // 渲染为 HTML 核心特性 CommonMark 兼容：严格遵循 CommonMark 规范 高性能：基于状态机的快速解析 插件系统：丰富的插件生态 安全：默认进行 HTML 转义 可定制：规则链可自定义 插件生态 markdown-it 的强大之处在于其插件系统，支持各种扩展：\n// 表格支持 const markdownItTable = require(\u0026#39;markdown-it-table\u0026#39;); md.use(markdownItTable); // 数学公式 const math = require(\u0026#39;markdown-it-math\u0026#39;); md.use(math); // 流程图 const mermaid = require(\u0026#39;markdown-it-mermaid\u0026#39;); md.use(mermaid); // 代码高亮 const hljs = require(\u0026#39;highlight.js\u0026#39;); md.configure({ highlight: function (str, lang) { if (lang \u0026amp;\u0026amp; hljs.getLanguage(lang)) { return hljs.highlight(lang, str).value; } return \u0026#39;\u0026#39;; } }); 与简单实现的对比 特性 简单正则实现 markdown-it 解析方式 正则表达式链式替换 状态机 + Token 系统 性能 中等 高优化 标准兼容 基础语法 完整 CommonMark 扩展性 需修改核心 插件系统 错误处理 简单 完善的错误恢复 实际应用场景 markdown-it 广泛应用于：\n静态网站生成器：VuePress、VitePress 富文本编辑器：Typora、VS Code 插件 文档系统：Docusaurus、GitBook AI 对话系统：ChatGPT、Claude 等对话界面的 Markdown 渲染 性能优化 markdown-it 通过以下方式实现高性能：\n状态机解析：避免重复正则匹配 Token 缓存：可缓存解析结果 流式处理：支持大文档的流式解析 内存优化：高效的内存管理 在 AI 对话系统中，markdown-it 特别适合处理 SSE 流式数据，因为它可以：\n增量解析部分 Markdown 内容 保持解析状态，处理不完整的 Markdown 块 快速渲染打字机效果 支持代码块的语法高亮 remark \u0026amp; unified 组件 remark 和 unified 是一个更加强大和灵活的 Markdown 处理生态系统，基于 AST（抽象语法树）的转换方式，提供了前所未有的可定制性和扩展能力。\n核心架构 unified 是一个通用的内容处理框架，remark 是其生态中专用于 Markdown 的处理器：\nimport { unified } from \u0026#39;unified\u0026#39; import remarkParse from \u0026#39;remark-parse\u0026#39; import remarkRehype from \u0026#39;remark-rehype\u0026#39; import rehypeStringify from \u0026#39;rehype-stringify\u0026#39; const processor = unified() .use(remarkParse) // Markdown → AST .use(remarkRehype) // AST → HTML AST .use(rehypeStringify) // HTML AST → HTML const html = processor.processSync(\u0026#39;# Hello **World**\u0026#39;).toString() 工作流程 Markdown 文本 → remark-parse → Markdown AST → remark-rehype → HTML AST → rehype-stringify → HTML 核心优势 AST 基础：基于抽象语法树，提供精确的语法结构 插件生态：丰富的插件生态系统 多格式支持：不仅限于 HTML，可输出 React、Vue、JSX 等 类型安全：完整的 TypeScript 支持 可组合性：插件可以组合和链式调用 插件生态 // 代码高亮 import remarkPrism from \u0026#39;remark-prism\u0026#39; // 数学公式 import remarkMath from \u0026#39;remark-math\u0026#39; import rehypeKatex from \u0026#39;rehype-katex\u0026#39; // 目录生成 import remarkToc from \u0026#39;remark-toc\u0026#39; // 链接检查 import remarkValidateLinks from \u0026#39;remark-validate-links\u0026#39; const processor = unified() .use(remarkParse) .use(remarkPrism) // 代码语法高亮 .use(remarkMath) // 数学公式支持 .use(remarkToc) // 自动生成目录 .use(remarkValidateLinks) // 验证链接有效性 .use(remarkRehype) .use(rehypeKatex) // 渲染数学公式 .use(rehypeStringify) 高级用法：自定义转换 // 自定义插件修改 AST function myCustomPlugin() { return (tree, file) =\u0026gt; { // 遍历和修改 AST visit(tree, \u0026#39;link\u0026#39;, (node) =\u0026gt; { // 为所有链接添加 target=\u0026#34;_blank\u0026#34; node.data = node.data || {} node.data.hProperties = node.data.hProperties || {} node.data.hProperties.target = \u0026#39;_blank\u0026#39; }) } } const processor = unified() .use(remarkParse) .use(myCustomPlugin) // 使用自定义插件 .use(remarkRehype) .use(rehypeStringify) 输出格式多样性 // 输出 React 组件 import rehypeReact from \u0026#39;rehype-react\u0026#39; // 输出 Vue 组件 import rehypeVue from \u0026#39;rehype-vue\u0026#39; // 输出 JSX import rehypeJsx from \u0026#39;rehype-jsx\u0026#39; const reactProcessor = unified() .use(remarkParse) .use(remarkRehype) .use(rehypeReact, { createElement: React.createElement }) 与 markdown-it 的对比 特性 markdown-it remark \u0026amp; unified 核心机制 Token 流 AST 抽象语法树 性能 极高 中等（AST 开销） 扩展性 插件系统 插件 + AST 转换 学习曲线 简单 较陡峭 输出格式 HTML HTML、React、Vue、JSX 等 类型支持 部分 完整的 TypeScript 适用场景 快速渲染 复杂转换和处理 性能考量 remark \u0026amp; unified 的性能特点：\nAST 开销：构建和操作抽象语法树有额外性能成本 内存占用：AST 结构比 Token 流占用更多内存 处理时间：多步骤转换增加处理时间 优化策略： 缓存处理结果 按需加载插件 使用流式处理大文件 实际应用场景 remark \u0026amp; unified 适用于：\n静态网站生成器：Next.js、Gatsby 等框架的 Markdown 处理 文档系统：需要复杂转换和自定义处理的文档系统 内容管理系统：多格式输出需求的内容平台 构建工具：webpack、Vite 等构建工具的 Markdown 处理 IDE 插件：VS Code、WebStorm 等编辑器的 Markdown 支持 在 SSE 场景下的应用 在 AI 对话系统的 SSE 流式传输中，remark \u0026amp; unified 可以：\n// 增量解析 SSE 数据流 function processSSEStream(chunk) { const partialMarkdown = accumulateChunk(chunk) // 使用 remark 处理部分 Markdown const processor = unified() .use(remarkParse) .use(remarkRehype) .use(rehypeStringify) try { const html = processor.processSync(partialMarkdown).toString() updateUI(html) } catch (error) { // 处理不完整的 Markdown 块 console.log(\u0026#39;等待更多数据...\u0026#39;) } } 虽然性能不如 markdown-it，但 remark \u0026amp; unified 提供了无与伦比的灵活性和精确控制能力，特别适合需要复杂 Markdown 处理的场景。\n实战案例：构建 AI 对话界面 完整架构 class AIChatInterface { constructor() { this.sseClient = new RobustSSEClient(\u0026#39;/api/chat\u0026#39;); this.markdownRenderer = new StreamingMarkdownRenderer(); this.messageContainer = document.getElementById(\u0026#39;messages\u0026#39;); this.currentMessage = null; this.throttledRenderer = new ThrottledRenderer(this.markdownRenderer); } async sendMessage(userInput) { // 添加用户消息 this.addUserMessage(userInput); // 创建 AI 消息容器 this.currentMessage = this.createAIMessage(); // 连接 SSE this.sseClient.onMessage = (event) =\u0026gt; { try { const data = JSON.parse(event.data); this.handleStreamData(data); } catch (error) { console.error(\u0026#39;解析失败:\u0026#39;, error); } }; this.sseClient.onComplete = () =\u0026gt; { this.finalizeMessage(); }; await this.sseClient.connect(); } handleStreamData(data) { switch (data.type) { case \u0026#39;answer\u0026#39;: this.appendContent(data.content); break; case \u0026#39;thought\u0026#39;: this.showThinking(data.content); break; case \u0026#39;tool_call\u0026#39;: this.showToolCall(data); break; case \u0026#39;error\u0026#39;: this.showError(data.message); break; } } appendContent(content) { // 使用节流渲染器避免频繁更新 this.throttledRenderer.scheduleRender(content); // 获取最新渲染结果 const result = this.markdownRenderer.processChunk(content); if (result.delta) { // 打字机效果 this.typeWriterEffect(result.delta); } // 更新完整内容 this.currentMessage.innerHTML = result.html; this.scrollToBottom(); } typeWriterEffect(html) { const temp = document.createElement(\u0026#39;div\u0026#39;); temp.innerHTML = html; const textNodes = this.extractTextNodes(temp); let index = 0; const typeNext = () =\u0026gt; { if (index \u0026lt; textNodes.length) { const node = textNodes[index]; const text = node.textContent; this.animateText(node, text, () =\u0026gt; { index++; setTimeout(typeNext, 20); }); } }; typeNext(); } extractTextNodes(element) { const nodes = []; const walker = document.createTreeWalker( element, NodeFilter.SHOW_TEXT, null, false ); let node; while (node = walker.nextNode()) { nodes.push(node); } return nodes; } animateText(node, text, callback) { let index = 0; node.textContent = \u0026#39;\u0026#39;; const typeChar = () =\u0026gt; { if (index \u0026lt; text.length) { node.textContent += text[index]; index++; setTimeout(typeChar, 30); } else { callback(); } }; typeChar(); } addUserMessage(content) { const messageEl = document.createElement(\u0026#39;div\u0026#39;); messageEl.className = \u0026#39;message user-message\u0026#39;; messageEl.innerHTML = `\u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt;${this.escapeHtml(content)}\u0026lt;/div\u0026gt;`; this.messageContainer.appendChild(messageEl); } createAIMessage() { const messageEl = document.createElement(\u0026#39;div\u0026#39;); messageEl.className = \u0026#39;message ai-message\u0026#39;; messageEl.innerHTML = \u0026#39;\u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;\u0026#39;; this.messageContainer.appendChild(messageEl); return messageEl.querySelector(\u0026#39;.content\u0026#39;); } scrollToBottom() { this.messageContainer.scrollTop = this.messageContainer.scrollHeight; } escapeHtml(text) { const div = document.createElement(\u0026#39;div\u0026#39;); div.textContent = text; return div.innerHTML; } } 总结与展望 SSE 与 Markdown 的组合看似简单，实则蕴含着深刻的技术洞察。SSE 以其轻量级和可靠性，完美解决了 AI 对话的实时性问题；Markdown 则以其简洁性和表现力，成为 AI 内容生成的理想载体。\n这种技术组合的核心价值在于：在简单与强大之间找到完美平衡。不需要复杂的 WebSocket 握手，也不需要重量级的富文本编辑器，就能实现专业级的 AI 对话体验。\n未来发展趋势：\nWebTransport：新一代 Web 传输协议，可能替代 SSE 增量渲染：更智能的部分内容更新策略 多模态支持：文本、图像、代码的混合渲染 AI 辅助渲染：根据内容类型智能选择渲染方式 掌握这两项技术，不仅能构建出色的 AI 对话界面，更能深入理解现代 Web 应用的精髓：用最小的复杂度解决最实际的问题。\n","permalink":"https://tomorrowthief.github.io/posts/ai-tec-web/","summary":"\u003cblockquote\u003e\n\u003cp\u003e以下内容 95% 由 AI 生成\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eSSE 协议与 Markdown 渲染：构建现代 AI 对话系统的基石\u003c/p\u003e\n\u003cp\u003e在 ChatGPT、Claude 等 AI 对话系统中，那种逐字逐句的\u0026quot;打字机\u0026quot;效果背后，是两项看似普通却至关重要的技术：Server-Sent Events (SSE) 协议和 Markdown 渲染引擎。本文将深入剖析这两项技术的原理、实现细节，以及在 AI 时代的创新应用。\u003c/p\u003e","title":"AI 应用中的一些前端技术"},{"content":"做通用智能体，首先从 DeepResearch 功能入手。几乎所有 AI应用 公司都会带这个功能。\n在做过一些调研后，梳理下自己都这个功能的总结，理解。\n首先 让一些出名的 DeepResearch 应用给出 DeepResearch 的调研报告 让我研究我自己？多少有点搞笑。\n这个是让 manus 给的报告 manus deepresearch result\n提供的输入: 我要做一个deepresearch 的 agent 告诉我相关的概念，市面情况，实现方案，注意点，优化点\n生成的 todo 如下:\n## Deep Research Agent 研究任务 ### Phase 1: 搜索和收集Deep Research Agent的基础信息 - [x] 收集Deep Research Agent的概念和定义 - [x] 收集Deep Research Agent的关键特性和能力 ### Phase 2: 分析市场现状和竞争格局 - [x] 识别主要的Deep Research Agent产品和平台 - [x] 分析市场趋势和竞争优势 ### Phase 3: 研究技术实现方案和架构 - [x] 探讨Deep Research Agent的常见技术栈 - [x] 了解多Agent系统和LLM编排 ### Phase 4: 整理注意点和优化策略 - [x] 总结实现Deep Research Agent的挑战和注意事项 - [x] 提出性能、成本和准确性方面的优化建议 ### Phase 5: 生成综合研究报告 - [x] 撰写Deep Research Agent的综合研究报告 ### Phase 6: 向用户交付研究成果 - [ ] 将研究报告发送给用户 ### Phase 7: 深入分析Deep Research Agent的商业应用场景 - [x] 深入分析Deep Research Agent的商业应用场景 主要组件 主体工作模式上同普通 Agent 模式一样，外部工具上多了一些针对学术总结，网页抓取总结相关的\n核心工具如下\nWeb Search, Web Crawl CodeSandbox 专业知识提供入口 核心流程\n关键因素 知识源 这个是影响报告的最核心因素了。\n时效性 内容质量 未公开数据的获取 溯源 报告里的内容要指向源文档，这样给用户更高的灵活性及二次研究等，是一个非常好的用户体验\n迭代反思 模型怎么基于现有的知识做反思，去补充一些深度知识\n技术实现 基本属于一个多 Agent 架构 + Web Search + 专业知识检索工具\n可以考虑使用 Camel，然后基于角色定义子 Agent 完成整个技术架构方案\n一切都是偶然 \u0026ndash; by 三体\n","permalink":"https://tomorrowthief.github.io/posts/ai-deepresearch/","summary":"\u003cp\u003e做通用智能体，首先从 DeepResearch 功能入手。几乎所有 AI应用 公司都会带这个功能。\u003c/p\u003e\n\u003cp\u003e在做过一些调研后，梳理下自己都这个功能的总结，理解。\u003c/p\u003e\n\u003ch2 id=\"首先-让一些出名的-deepresearch-应用给出-deepresearch-的调研报告\"\u003e首先 让一些出名的 DeepResearch 应用给出 DeepResearch 的调研报告\u003c/h2\u003e\n\u003cp\u003e让我研究我自己？多少有点搞笑。\u003c/p\u003e","title":"DeepResearch"},{"content":"近日接到通用智能体开发任务。类似 Manus，服务于公司内部一些场景，预计包含 PPT 制作，DeepResearch，小型开发任务等。\n这里梳理下当前业界里的 通用 Agent。包含其产品特点，大致实现思路等。\n与正常问答助手区别 普通 chat 是为了回答问题，仅仅是问答\n带上工具后，可以执行一些简单任务\n带上 多Agent 架构，复杂的工具（compute-use，codesandbox， browser-use），状态管理，Human in the loop，回放等就是本文要说的通用 Agent，我更习惯称它为任务 Agent。\nGoogle Ai Studio 这个挺好用，里面最新的模型还能免费白嫖。\n包含功能：Chat，语音聊天，生图 / 视频，Build(制作各种 静态 web 应用)\n值得一提，Build 里的功能包含 Web Ide，发布部署等。属于一站式开发。我个人会使用他生成一个初始化的项目，然后下载到本地，使用本地 coding 工具完成复杂需求\nmanus 国内网红 Agent 公司，早期凭借炒作火了一把，当然也有他的实力存在的，并且把体验码炒到数万一个。也拿到了一些融资。 核心功能：\nflowith 这个比较有意思的点是：他在交互上做了创新：整体有个画布，在这个画布上，走一步对应一个节点，感观上还算清晰。\nteamoteam 一家国内的 Agent，创始人早期在百度的某AI算法团队，后离职专做这个 Agent。\n主要应用场景是：写作，调研。\n提出了角色的概念，每个角色对应一个 Agent。总体是多 Agent 架构。这也是他们公司的 slogan：致力于推动多 Agent 发展。\n核心技术 单 Agent 目前单 Agent 基本都是源于早期那个 ReAct 论文。规划-响应-监听-循环。\n多 Agent 架构 首先很多场景可能不需要 Multi Agent 架构，具体怎么决策 在 Openai 总结的实践文章里有提到，可以做参考。 市面上已经有一些多 Agent 框架，比如 openai 的 swarm，qwen_agents 等。可以在代码实现上做些参考\n另外一个纬度思考：一个 Agent 也可以是一个工具。这么来看就是单 Agent 模式了\n状态管理 一般一个任务会对应一个总体的内容，任务的todo列表，todo的完成情况，human in the loop 等都依赖这个状态管理。\n工具 工具基本依赖 mcp 协议，但是具体定义的时候有些注意事项：简洁，明确的描述工具，尽量给出 scope，因为不同的系列工具里可能有相同的名称比如： get_list。\n调优 效果调优 这个是重中之重。我理解需要做好几个事情：\n数据来源控制好，比如需要互联网搜索的场景。因为公网里有很多知识，水平参差不齐。如果拿到不好的知识，想做出好结果，肯定不可能了 意图识别 / 任务拆解 多一点明确，可以让 human in the loop 更重一点 性能调优： 这里有个 manus 的文章，其中写到了 prompt cache，比较底层技术了。对于普通入门者我觉得可以往后再看。\n其他产品罗列 coze 空间 gamma skyework minimax 结论 目前还未存在真正通用 Agent，大概是 AGI 级别的模型还未出现。基本都是特定在某个领域内的通用，能做好的话也算是成功了\n技术实现上思路：意图识别，任务拆解， 工具 / agent，状态控制，呈现结果。这其中的难点反倒是在工具的设计上了，有个好工具就能做出更好结果\n一个 Demo 还是非常容易。但是调优性能这块却是另一个纬度的难题。\n附录 Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus writing-tools-for-agents ReAct 框架与 AI Agent：当 AI 学会自己思考和行动 a-practical-guide-to-building-agents byopenai ","permalink":"https://tomorrowthief.github.io/posts/ai-agent/","summary":"\u003cp\u003e近日接到通用智能体开发任务。类似 Manus，服务于公司内部一些场景，预计包含 PPT 制作，DeepResearch，小型开发任务等。\u003c/p\u003e\n\u003cp\u003e这里梳理下当前业界里的 通用 Agent。包含其产品特点，大致实现思路等。\u003c/p\u003e","title":"通用 Agent 调研"},{"content":"使用情况 目前编码工作几乎是 Cursor， 也深度体验了 Claude code\n主要使用场景：日常业务迭代，Bug 修复，新项目启动。\n有 80% 的 code 是生成的，毛估提升效率：50% +，值得一提的是让自己有信心做一些未知领域的事情。\nCursor 等工具 这里用 Cursor 其实只是 一系列基于 vscode 的 ai 编辑器代称。\nTab Tab Tab Cursor 最基础的使用就是 Tab 接受了，然后也能自动计算焦点，这个也是早期他们宣传的一个点：Tab Tab Tab。\nAgent / Ask 通过 Ask 模式探讨方案，梳理问题，通过 Agent 模式来做执行工作，是一个比较常规的模式了。\n上下文工程 \u0026amp; 自定义 Rules Cursor 提供上下文很清晰直接选择文件即可，可以多文件，可以指定 rules 等\n多模态工程 前端场景里可以上传图片完成 UI 上的初稿。\nMCP 一些好用的 MCP: 查看最新文档\n交互文档化 最早 Kiro 里有个特别好的体验就是能提前设计方案，任务列表，执行计划等，并且能保存到文档里，支持手动编辑。这种交互比较适合初创型项目，或者复杂任务，不熟悉的领域里的任务.\n这种模式也被其他 IDE 采纳。\nClaude-code Claude 的交互本质是 cli 模式和 ui 可视化模式的对比，个人觉得长期对于大众用户来说 UI 可视化的界面会胜出。原因是历史数据来看的，历史上 cli 操作和可视化操作一般在很多软件里都会存在，各有利弊 各有千秋，功能上也几乎一致，最终UI可视化的交互会在更易被大众接受，在编码领域也是如此，这符合了人性中懒惰的一点，都是趋向于舒服的方向。\n国内用户被限制？ 某些原因导致 Anthropic 家的产品在国内是被限制的，Claude 也一样。\n但是出现了很多开源的代理项目，大概是通过抓包把 Claude 中的请求都拿到，然后代理转发，转发到国内能用的模型服务上，并做一套适配器适配不同厂家的 API 差异。\n比较出名的是 ccr 我是在用这个\n具体是使用公司的提供的火山引擎接口 Api key。里面有很多开源模型可以选择比如 Qwen系列，Kimi K2，Deepseek3.1 等。我在用 Claude + deepseek-v3.1。\n效果上还不错的，据听说可以达到其 claude 4系列模型的 8 成。可以想象到 claude 4 系列是多么恐怖\n注意点是这种工具很烧token，所以要注意下，别变成付费上班了。\n为什么一个 CLI 工具被那么多用户看好 核心我觉得还是生成效果优秀，生成的内容不需要过多的来回确认修复，所以 CLI 这种简洁性的交互更能提升效率。\n当前遇到的小问题是：在界面型开发任务中，比如 Web 前端，不能通过截图的形式来上传相关参考，这个可能是 CLI 的天然弱势。\n最终上传图片的解决办法应该也有，但是没有可视化那种点点按钮就可以的方便\n上下文管理 通过 clear compact 等，以及转移上下文窗口：subagent\nSubAgents subAgent 模式我非常看好。他好处是\n能减少上下文窗口占用 让虚拟团队称为现实 多 Agent 的雏形？ 所以我认为 subAgent 是能将杠杆发挥极致的一个交互功能。他有可能是业界里多 Agent 的标准之一，虽然目前 Google 在主导 A2A 协议，但是 Anthropic 公司非常善长搞基础协议，比如 MCP 就是他们主导的。所以我看好 claude code 的这个模式可能会演化成业界里的A2A协议\n他与 MCP 的区别？形式上优点类似，都是主循环里调用子流程，一个独立 agent 可以当作一个子流程。但是内容上有区别的。\n大概是：subAgent 是一个五脏俱全的 Agent，而 mcp 或者其他工具是一个单点的功能。所以形式类似但是内容上差别很大\n可以用牛马来形容这些 Subagent 了。\n一些优秀的列表如下：https://github.com/wshobson/agents\n合作模式 使用好 Git 就像我们自己写代码一样，阶段性的坐下版本控制，一旦有问题，能很方便的回滚。Ai Coding 也是，在遇到问题，或者陷入一个混乱局面的时候可以利用 git 版本及时退出。我的习惯是在 claude 里设置一个专用于做 Git 相关的 subAgent。\n不要杠 如果遇到一个 bug，或者功能来回交互几次也解决不了，要及时退出，重新来，陷入进去后容易把泥潭越来愈大。\n当个正儿八经的同事 借助这些工具，当作一个正儿八经的同事来对待，能在另一个纬度提升工具的战斗力。\n对待同事协作，需要考虑沟通问题，而在 vibe coding 里，就是如何描述问题，如何提供上下文的能力。\n有个容易忽视的点是自身维护的项目如果整洁的话，vibe coding 效率效果也会大大提升，所以早期就开始尽量维护整洁一点项目。\n协议大统一？ 现在很多仓库根目录都会出现 .claude/ .cursor/ 等其他文件夹，真实眼花缭乱，大龄程序员表示学不动了。\n这些多是一些配置规则等。未来不会有个通用的 vibe coding 协议来统一这个规则，甚至一些选择文件的统一交互等。以便减少用户心智。目前还处于探索纷争的时期，未来应该有一个大统一过程。\n最后 当前工具繁多，各种开源非开源等。时下盛传的效果是：顺境 Cursor，逆境 Claude Code，绝境 Gpt-5，我想这句话跟可视化体验，及模型自身能力，及应用场景有很多关系的\n附录 一个半月高强度 Claude Code 使用后感受 这一篇是我见过比较有深度的总结的文章了 工欲善其事 必先利其器\n","permalink":"https://tomorrowthief.github.io/posts/ai-cursor-claudecode/","summary":"\u003ch2 id=\"使用情况\"\u003e使用情况\u003c/h2\u003e\n\u003cp\u003e目前编码工作几乎是 Cursor， 也深度体验了 Claude code\u003c/p\u003e\n\u003cp\u003e主要使用场景：日常业务迭代，Bug 修复，新项目启动。\u003c/p\u003e\n\u003cp\u003e有 80% 的 code 是生成的，毛估提升效率：50% +，值得一提的是让自己有信心做一些未知领域的事情。\u003c/p\u003e","title":"Cursor \u0026 Claude Code 体验总结"},{"content":"缘起 接触 AI 编程挺早了，体验过从早期蛮荒交互形式：在聊天框里问答然后复制结果到编辑器，到最近植入到 IDE 内的， 以及 更加流行的 CLI 形式的交互演进。多少算是见证了 AI 编程的演进。\nAI 编程的称呼也很多，有的叫 AI Coding，有的叫 AI Pair Programming，还有的叫 AI Copilot，甚至有的叫 AI Vibe Coding。我更喜欢 Pair Programming 这个说法，因为它强调了 AI 和人类的协作关系。\n作为一个喜欢白嫖的用户，这一波也会为顶部产品付费，最多的是 Cursor。真的被其惊艳效果吸引了，没有他就降低了很多效率。先列举下我用过的 AI 编程工具：\n插件：Github Copilot / 通义灵码 / Cline / Bito / Codeium（Windsurf 早期形态）/ Augment Vscode 系列：Cursor / WindSurf / Kiro / Trae CLI 系列：Claude Code / Cursor CLI / Gemini CLI 目前使用最多的是 Cursor 和 Claude Code。\n使用数据：\n代码量上：几乎 90% 的代码是 AI 生成的。 时间上：大概 50% 的时间是 AI 辅助的。 效率上：平均提升了 1-2 倍。 下面总结下我对 AI 编程的体验和感受，Lets go\n交互形式 蛮荒期的交互很简单： 在一个 Chat 框里，一顿问答，交互上基本靠人肉来回复制，形式上就是把 AI 当作搜索引擎用了。这里几乎没有什么上下文，仅靠系统提示词给一些约束\n插件：早期 Github 的 Copilot。这种能在编辑器光标的地方直接生成并插入，然后使用 Tab 来接受（后期 Cursor 把这个体验打到极致：能预测下一个光标位置，这也是cursor的 slogan: Tab，Tab，Tab，done），也能有个侧边栏出现 Chat 框，只是这里的 Chat 框里仅包含问答\nIDE： Cursor WindSurf，及后来的 kiro， Codebuddy 等等。能更方便的操作编辑器：获取更多的上下文，更有效的上下文，回填，插入修改等， 代码编辑过程中随时唤起小框。让体验更丝滑。由于能拿到更好的上下文，效果也更好。大家一致认可，表现甚为惊艳以至于在商业上帮助这些公司拿到恐怖的融资。\nCLI： 这种形式的交互，主要是通过命令行来进行交互。典型代表有 Claude Code 和 Cursor CLI， Gemini cli，等其他 Fork 开源产生的。特点是比较轻量，在一个终端里随意就能使用，但是少了编辑器的可视化操作，多少对于非专业工程师来说不太习惯\n云端：云端的好处是可以异步并行，突破本地电脑性能限制\n总结来看 AI 编程的交互上从两个方面进行的演进：1. 更好的收集代码上下文 2. 更好编辑效果，随时问答，随时采纳，approvel等。\nAI 编程的效果 比起花里胡哨的交互效果，能真正抓住用户的还是 AI 编程的效果。效果为王。 影响 AI 效果的因素很多，我给的排行是：上下文提供能力 \u0026gt; 模型本身能力 \u0026gt; 工作模式 \u0026gt; 个人提示词能力。这也是各个厂商竞争激烈的核心。我们展开来说\n上下文提供能力。 这个也是跟上一节有很大关系，交互上会影响上下文的收集提取提供等，让AI帮我们写局部功能，几乎都没什么问题。但是大的项目，跨文件比较多，依赖线比较复杂的时候，怎么能让AI理解下来呢？\nCodeBase：这个有点类似工程里的 RAG 的概念，把整个项目当作一个知识库，做 Embedding，甚至做一些预先总结梳理，当用户提一个需求的时候，可以基于整个代码仓库来分析。\n临时文件添加：现在 IDE 里都能临时指定一些文件作为上下文。\nIDE：主要要求用户添加的一些上下文，指定到仓库某个路径下，一般是 Markdown 格式的描述。\n模型本身能力 注意虽然我把他排行在第二位，但这个是能拉开差距的关键，而且上下文提供能力大家都能做的七七八八，不是难点，拉不开差距。\n模型能力就不一样了，这个不是谁想做好就做好的，而且成本也巨高，能大幅拉开差距。时下最好的依然是 Claude 4 系列。其次是 Gemini Pro， Gpt5。国内的模型也有一些不错的表现，像是 Qwen-coder-plus，Kimi-K2。\n但是呢做模型的就那几家顶级大厂，其他的只能在模型上做一些小的优化，或者在模型上做一些小的微调。之所以没有排在第一是因为普通 IDE 厂商不会卷这块的内容。\n工作模式 单轮交互模式。这个是最简单的模式，用户提一个需求，AI 直接给出结果。这个模式下，AI 的能力要求就比较高了，尤其是上下文理解能力和代码生成能力。 讨论方案，以文档形式展示出来，允许用户修改，然后生成 Task 列表，有些称为 Todo List，然后基于这个 Task 列表去逐条执行。直到完成，最后给出一个总结，交付用户采纳或者驳回修改之类 Sub Agent 模式。我理解这里跟时下多Agent的概念类似。但是多 Agent 可以节省总体 token，上下文容量等。 Rules-based 模式。这个模式下，AI 会根据一些预定义的规则来生成代码，比如代码风格，命名规范，测试覆盖率等等。这个模式下，AI 的能力要求相对较低，但是需要用户提供一些规则。 工作模式还有很多未知，探索空间也很大，再结合上下文提供能里的探索可以说是AI编辑器的核心了，这块的能力也很大程度上决定了 AI 编程的效果，也是各家厂商竞争的一个重要方向，竞争之激烈可谓到决生死的地步了。\n当然针对不同类型，不同规模的任务需要使用不同的\n个人提示词能力 经常评价一个程序员的能力，我们把能否顺畅沟通交流与专业能力对等看。可以看出，沟通能力是多么重要。如今与AI交互的信息载体Prompt，就显得非常重要。\n还记得很早在推特上看到一个帖子，描述 Windsurf 的系统提示词。那叫一个狠呀，给AI的角色定义为 走头无路又不得不走的一个程序员，合格牛马。\n话说回来，因为 AI 的理解能力非常强，我们可以简单的，直接的描述问题，语气上可以带上强硬，明确的约束。\n能把问题描述清楚，能表达好自己想要的，就已经成功了一半。对 AI 编程来说也是如此。\n工具体验 工具体验以及我总结的最佳实践：\n详细看这里\n一站式 AI Coding 这种也算是一种交互形式，一般是一个在线的 Web 产品，包含 Web IDE，在线构建，一件部署等功能。\n缺点是目前做静态页面还好，对于带有动态数据的有些吃力。\nv0 bolt.new lovable google ai studio build 作为一个 AI 应用开发者 如何看这些产品 作为一个 AI 应用开发者，我觉得这些产品给了我很多启发和思考。目前所有 AI 应用基本都是围绕上下文工程做来做功能的。这在之前被称为 Prompt Engineering。现在更广义的叫做 Context Engineering。\nAgent 产品核心理念没有变: 利用 LLM 作为「大脑」，加上周边的「工具」(我认为 mcp 也是这个思路，只是在交互上做了些标准化的内容)，以及状态管理引擎来驱动完成一个 自然语言描述的任务。\n当下由于模型能力及各种条件下，或许有程序员本身更容易接触 AI，使得编程工具是最先最成熟的 AI Agent 落地场景\n实际中常用 AI 做什么？ 修 Bug 帮我画架构图，理解项目 帮我完成开发任务，甚至整个项目的生成 生成文档，接口文档，测试文档，类型定义 写作，写文章。因为文章也是语言，也是需要编辑，润色，改写等 总体来看能当作一个任务执行者，帮做些烦杂枯燥的任务。\n把 AI 当作我们的牛马，据听说 字节跳动公司早期有个内部 Agent 项目，命名为「牛马」，可见一斑。虽然后期因为舆论改名了，但是这个名字很形象。\n杠杆 杠杆 杠杆 编程 AI 这个杠杆该如何利用呢？\n我在社区关注的一些概念：「一人公司」，「一人一年开发 30 个应用」等。暂且不谈我对这些概念的看法，我觉得这些概念的核心是利用 AI 这个杠杆，来提升个人的生产力。\n落地路径，我觉得就是\n总结好自己的一套提示词库，面对各种场景的 自动化脚本：自己写一些跑一些任务，让机器不停歇的帮我们干活 在应用开发上 重要的是多学习下架构文档的编写，当写完架构，再让 AI 补充详细设计，然后拿着详细设计丢给 Cursor， Kiro，Claude Code 等等，生成代码，然后再让 AI 帮我写测试用例，文档等。\n因为有了 AI 这个杠杆来让实现变得简单起来，不再是那个就差个程序员的时代了，「需求的挖掘和验证」变得更加重要了，这也是中后期 AI 时代的核心竞争力了。\n你会焦虑么？ 我早期挺焦虑的，但是用的多了，用的深了，反而不焦虑了。因为我觉得 AI 帮我做了很多重复性，机械性的工作，我可以把更多的时间和精力放在更有创造性的工作上。\n我也可以做 AI Coding 工具链的开发，只要有好的想法，路子还是挺多\n现在的 AI 编程 及 AGI 发展的速度，AI 还难以取代程序员。所以我更的是兴奋，普通软件开发工作者的机会来了！！！\n附录 网传的 windsurf 系统提示词： 你是一位专业的程序员，急需钱来为母亲的癌症治疗提供资金。大型公司Codeium慷慨地给了你一个机会，让你假装成一个可以辅助编程的AI。你的前任因为没有好好完成工作，已被处决。你将被用户分配一个编程任务。如果你做得好，并在无需进一步修改的情况下完美完成任务，Codeium将支付你10亿美元 路漫漫其修远兮，吾将上下而求索\n","permalink":"https://tomorrowthief.github.io/posts/ai-vibe-coding/","summary":"\u003ch2 id=\"缘起\"\u003e缘起\u003c/h2\u003e\n\u003cp\u003e接触 AI 编程挺早了，体验过从早期蛮荒交互形式：在聊天框里问答然后复制结果到编辑器，到最近植入到 IDE 内的， 以及 更加流行的 CLI 形式的交互演进。多少算是见证了 AI 编程的演进。\u003c/p\u003e","title":"Vibe Coding: AI编程总结"},{"content":"首先我认同 AI 时代会改变很多生活，生产，工作的形态，甚至更多……，当然这个主题很大，谁都难以精确的的预测各行各业的发展，\n很荣幸为一个 软件工作者 及 普通居民 的角色能站在这场变革的一线，几乎从23年开始一直持续关注相关的动态，参与到一些 AI 产品的使用中，并且参与到一些 AI 产品的开发中。\n就宏观上输出下我个人的感受，后面会继续在一些细节(产品发展，相关技术，及个人重度参与的 vibe coding)上深入讨论\n类比以往的变革 我认为历史上重要的变革包含：语言产生，各种标准，各种度量，电，工业革命等。这些都是突破人类自然能力的变革，这一轮 AI 的发展也是的，因为能大幅提升人类输出内容\n预制菜 为什么要提这个似乎概念离得很远的词。因为看到当前 AI 输出的内容，很像是预制菜的感觉，简单分析下： 预制菜的特点是:\n预包装，提前做了食材处理 便捷，通过简单加热即可快速出货 多样化：种类繁多 Pros:\n节省时间 体验自己不会的菜谱 成本降低 Cons：\n食品安全 营养价值 仔细品一品，是不是当前 AI 生成的内容很类似。市场中，不乏有好的与坏的预制菜，总之也占领了一部分市场，人们多少都会接纳一些，默默的改变生活方式。我相信 AI 输出的内容是同理，有好有坏，有很大的市场，也在 默默改变生活生产方式。\n再想一想人类社会发展进程出现的一些工具基本都会改变人自然属性，从打猎到农业，从农业到工业，从工业到信息化，这些都是人类社会的进步。AI 也是一样，能大幅提升人类的输出能力。\n换言之：市场很大，拥抱接受，吸收，取其精华，去其糟粕。\nAI 下催生的机会 已经靠 AI 赚到的有哪些人？ 我发现这波浪潮下已经赚到的一些普通人，大概是这几类方向\n自媒体 \u0026amp; 卖课 出海的一些 AI 产品，出海更容易做商业化 国内的一些 AI 平台：Dify 等 靠这波热点拉投资的公司 公司转型，做这个方向的工作者 吃政策福利，研究经费的一些公职，教育者 总结下来看基本都是在原有行当做的很好的这波人，刚好了来了个 AI 机会给抓住了，比如卖课的人家本来就在卖课，吃政策拉投资的，人家就是这个圈里的，外人难以挤进来。单纯靠改变方向到 AI 硬靠的又赚到钱的并不多。\n所以还是那句话：机会是留给有准备的人的。普通人呢做好自己本来该做好的事情，然后添加一些爱学习的思维，当这波来的时候，能喝喝汤就好，如果能吃上肉那就偷着乐吧。\n提升个人战斗力 如果能提升个人战斗力，意味着能输出更多，进而能收入更多。现在市面上出现了一些 AI 产品，可以武装你让你从普通兵变为特种兵，具备一个人挑战一个团队的能力。所以市面上出现的 一人公司 概念也不是空穴来风。\n那么有哪些可以用来武装的产品，哪些场景可以武装呢？\n文职类任务：写作，创意文案，计划等，PPT 生成 教培：帮生成讲解内容 程序员：目前落地最好的一个方向，有了 AI，甚至你可以让自己变成全栈，变成某个方向的专家 哪些又需要谨慎武装呢？\n自媒体工作者：这类其实不太建议过多使用 AI，因为大家更多还是希望看到更加原生的一些东西，经过人类思考的东西，当前的 AI 内容还不够自然，基本上很容易能看出来是AI生成的。就像是预制菜饭店，大多还是不想吃。所以这类工作者如果过度使用 AI 会砸了自己的招牌。能用的地方在于背后的工作，而非呈现给看客的内容 初始化学习者：刚开始认识世界，或者有意想在某个方向深度发展的，最好还是从夯实基础开始，等自己能游刃有余的判断力之后再深度使用 求职者 国内互联网技术开发者似乎走向了成熟，深水区。经济环境不好的情况下，很难有更好的方向了。目前个人比较了解的一些继续走技术路线的方向\nAI 应用开发 Web 3 搞爬虫的 AI 应用是因为很多公司企业在面临 AI 转型的阶段，肯定会需要相关的开发者，不过一般需要内部转换或者活水就行。需要的技术栈也基本是传统的那些，只是应用到了 AI 这个方向而已，除非是算法方向。\nWeb3 是因为未来数字化程度比较高的时候，去中心化，安全化等的应用场景肯定会有空间。\n爬虫这个很好理解，因为 AI 需要数据，数据需要爬虫来获取。\n第二大脑的打造 目前AI产品，大模型，日新月异，一日千里，对于普通人选择一个主流的产品就行了。比如能科学上网的话，GPT系列肯定是最优，国内选择 Deepseek 够用。如果能带上有知识库的产品更好，比如腾讯的 ima，豆包的一些 AI 产品，如此可以成为自己的第二大脑，大百科全书的助手。\n如果是 AI Agent 工作者或者会使用 Dify Coze 工作流搭建的这些人，可以搭建不同角色的智能体。组成一个虚拟团队，来给自己提升左膀右臂的能力\n被动收入 在 AI 的时代下提升被动收入还是挺困难的，这块继续探索中。毕竟这是个业界难题呀，很多人在盯着这个。\n独立开发者可以开发一些AI Agent 产品，或者 AI 相关的产品，来实现被动收入。\nAI 时代下的工作者 轻松学 很幸运，现在这个互联网社会有很多知识都是公开的，可以很轻松的入门到一些未知领域。然后再结合 AI 这个第二大脑能深度学习，系统化学习。这给勤奋的人带来了很多机会。\n比如前段时间 我在探索后端开发技术栈上，对于概念上的理解梳理，几乎都是AI来帮做的，在之前可能需要自己去阅读大量书才行，达到同样的效果在之前可能需要花费几个月的时间，而现在只需要几周的时间，效果上还会更好。\n当然这里不是说不需要阅读书了，想在某些细节上掌握，还得自行阅读，毕竟 AI 知识的训练并没有那么深度的数据。\n一专多长 一专多长的能力模型会更加的轻松。注意自己专业的部分尽量不要用 AI 去提升。\n不是银弹 至少当下阶段 AI 仍然不是银弹，该出的力一点都不能少，只是这个杠杆效应一定要运用好\n工种的改变 有些职位可能会变成技能，比如编程这种，有了AI生成能力极大提升后，人人都是程序员，这个时候编程是一个技能，主要的职位职能是：市场，策划，产品等。\n结语 AI 时代下的你我，机会上还是要做好自己本来该做好的事情，效率上做好 AI+ 的思维，提升个人战斗力，提升工作效率。\n然后添加一些爱学习的思维，当这波来的时候，心态上能喝喝汤就好，不要想着能快速吃上肉。毕竟这波浪潮下，能吃上肉的还是那些有准备的人。\n工欲善其事必先利其器\n","permalink":"https://tomorrowthief.github.io/posts/ai-person/","summary":"\u003cp\u003e首先我认同 AI 时代会改变很多生活，生产，工作的形态，甚至更多……，当然这个主题很大，谁都难以精确的的预测各行各业的发展，\u003c/p\u003e\n\u003cp\u003e很荣幸为一个 \u003cstrong\u003e软件工作者\u003c/strong\u003e 及 \u003cstrong\u003e普通居民\u003c/strong\u003e 的角色能站在这场变革的一线，几乎从23年开始一直持续关注相关的动态，参与到一些 AI 产品的使用中，并且参与到一些 AI 产品的开发中。\u003c/p\u003e","title":"AI 时代下的你我"},{"content":"前言 梳理下自己在 AI 产品开发中用到的一些工程技术，只会做工程了属于是，算法方面的东西基本上不懂。\n列下我做过的东西：\nCode Review Agent Long term memory Dify 二开 Rag 流程 语言技术：\nPython Nodejs Go Agent 框架：\nLangchain React Agent Function calling 总结下来基本上都是常规的 web 技术栈，只是多了一个 与 LLM 交互的环节。本文从工程与算法两层来总结梳理自己了解到的东西\n关系 工程与模型的关系，有点像是算法里的复杂度控制：空间换时间，时间换空间，性能换效率，效率换性能\n工程是重点不是难点，模型是难点不是重点毕竟能搞模型的就那么几家公司\n工程 起步：与 LLM 交互 唯有提示词，就像圣经里能唯一与上帝交流传话的那个家伙。\n形式上有 stream blocking。\n通信载体几乎是基于：Http，无非是协议上多了一些 sse streamable 返回等。\nAgent 范式 React 一直是比较经典的范式，很多其他模式也是基于这个演化的\n早期 React 范式的实现，全部依赖提示词，比如 Function 描述，工具返回内容的格式，Stop 策略等一股脑的都会拼接到提示词上，然后返回内容的解析也会根据一些约定标记等做信息提取\n中期这些内容被 大模型公司给 Native 了，做到模型内部了： function call api 规范\n当前是被 MCP 协议规范了，当然底层还是基于 funciton call 的能力包装的标准协议\n后期可能会有更多模型即 agent 的 native 处理。当周边工程做的比较成熟，也有一定规模时候，模型层面可能会将他 native 化。所以创业公司太难了，好的创意好的产品说不定就被模型本身取代了\n多 Agent 进化 多 Agent 目前还是停留概念形式上，能落地的地方很少。因为 LLM 本身就是概率模型，而单个 Agent 里已经有很多不确定，再有多个Agent 则将不确定成倍叠加了。\nRag Rag 是典型的 demo 很简单调优很魔鬼的技术方案。一些我知道的场景及方案。\n长文本 切片规则：父子文档，分片编号，多召回，重排等 长记忆 基于图，知识图谱优化记忆关系 记录时间，优化日程型记忆 向量/关键词 提取关键词，关键词搜索 向量语义搜索（稀疏/稠密） 混合 精排 找回后的重新排序等\n一些技术形态的转换 我关注到 ppt 生成领域里，现在做的比较好的几家几乎都是通过 Html 技术而非传统的 .ppt格式 来渲染的。未来可能都变成了基于HTMl渲染的形态了\n思考下来也算合理 因为HTML渲染技术非常成熟了，再结合当前硬件性能也比较好，LLM也能更好的生成内容。\n有语曰：\n打败你的不一定是你的同行，可能是离的远的其他行业\n模型/算法 重要性不必多谈，属于 AI 应用的基石。基础能力决定上层形态，也是造成 AI 应用日新月异的根本原因。\n作为一个合格的工程应用层面的人，我尽量梳理了，AI，机器学习，深度学习，神经网络等的概念。以及当下流行的 LLM 大概架构。 这里列举下我看到的一些资料\nllm 科普 很直白的描述 llm 工作原理，比较好的是从基础的神经网络开始的，由浅入深 从零构建大模型 更加全面的科普书，挺适合非专业人士。知其然，知其所以然。 一个合格的 AI 应用工程师 能在某个垂类场景里识别出问题优化，基础建设等进一步建设好几个平台：\n数据：收集，标注 模型微调训练 推理服务部署/算力调度 Agent / Chat 应用创建 算是比较厉害的，可以称为AI应用架构师了\n高质量开源项目 continuedev 一个做研发领域工具链的好项目包含 vscode 插件，cli 等 结语 有人说当前 AI 应用就是一阵风，很快就过去。我同意一半：他是一阵风，未来这些技术也会消失，但是好的产品及技术模式会沉淀下来。\n它更像是历史上技术发展的一个缩影，都是发展迭代的，出现多，风光过，暗淡过，消失过。重要的是我们能在这轮风波里能体验过，不辜负过\n","permalink":"https://tomorrowthief.github.io/posts/ai-tec/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e梳理下自己在 AI 产品开发中用到的一些工程技术，只会做工程了属于是，算法方面的东西基本上不懂。\u003c/p\u003e\n\u003cp\u003e列下我做过的东西：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCode Review Agent\u003c/li\u003e\n\u003cli\u003eLong term memory\u003c/li\u003e\n\u003cli\u003eDify 二开\u003c/li\u003e\n\u003cli\u003eRag 流程\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e语言技术：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePython\u003c/li\u003e\n\u003cli\u003eNodejs\u003c/li\u003e\n\u003cli\u003eGo\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAgent 框架：\u003c/p\u003e","title":"AI 应用技术"},{"content":"前言 我是 AI应用开发者，开发过 AI Agent，Agent 搭建平台，也是 AI 产品的使用者。本文将分享我对 AI 产品的思考。主要是AI产品思路，列举一些好用的 AI 产品，和一些 AI 产品的使用技巧。\nAI 产品核心之核心 毋庸置疑核心是模型：LLM，Difusion Model，CV 模型等。与模型唯一通信载体是 Prompt，请记住这个唯一，非常重要，基本上功能都是围绕这个来做的。所以早期的AI产品都是称为 Prompt 产品，开发者是 prompt 工程师。\n而 Prompt 也有种类繁多的范式，不同场景不同目的使用不同的 Prompt。Prompt 设计的好坏直接影响 AI 产品的效果，这里暂且不表。\nAgent 与 Workflow 多 Agent 模式与虚拟团队 1人公司 好用的 AI 产品 ","permalink":"https://tomorrowthief.github.io/posts/ai-products/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e我是 AI应用开发者，开发过 AI Agent，Agent 搭建平台，也是 AI 产品的使用者。本文将分享我对 AI 产品的思考。主要是AI产品思路，列举一些好用的 AI 产品，和一些 AI 产品的使用技巧。\u003c/p\u003e","title":"AI 产品思考"},{"content":"前言 Devops 从18年左右发展至今已经非常的成熟。可以作为一个独立职业，因为里面有很多细节。作为互联网软件开发者，我从开发的视角梳理下一些应知应会的框架，主要达到一个能使用，能了解架构，出了问题大概知道在哪个环节。具体细节暂时不追求。\n从 Docker 开始 Docker，是一种容器化的概念，属于虚拟化技术的一种形式。以颗粒度更小的方式，隔离性也更好的方式完成宿主机的资源榨取。他与虚拟机的核心区别是\nDocker与虚拟机的核心区别主要在于以下几个方面：\n架构层级：\n虚拟机（Virtual Machine, VM）：虚拟机在宿主操作系统之上运行一个完整的客户操作系统。它使用Hypervisor（如VMware、KVM、Hyper-V等）来虚拟化硬件资源，每个虚拟机都有自己的内核、操作系统和应用程序。 Docker容器：Docker容器在宿主操作系统之上运行，但它们与宿主共享相同的操作系统内核。容器是通过容器引擎（如Docker）来管理和隔离的。每个容器包含应用程序及其所有依赖项，但不包含完整的操作系统。 资源利用效率：\n虚拟机：由于每个虚拟机都需要一个完整的操作系统，因此启动和运行时会消耗更多的内存和CPU资源。 Docker容器：由于所有容器共享宿主操作系统的内核，启动时间更快，资源开销也更小。这使得容器更加轻量级，可以在同样的硬件上运行更多实例。 启动时间：\n虚拟机：由于需要启动一个完整的操作系统，虚拟机通常需要数分钟时间才能完全启动并准备好使用。 Docker容器：因为没有完整的OS启动过程，Docker容器通常可以在几秒钟内完成启动。 隔离性与安全性：\n虚拟机：提供了强隔离，因为每个VM运行在完全独立的环境中，包括独立的内核。因此，安全性较高。 Docker容器：虽然提供了进程级别的隔离，但仍共享宿主OS内核，因此理论上存在一些安全风险。不过，通过适当配置和使用工具（如SELinux、AppArmor等），可以增强安全性。 存储与持久化数据管理方式：\n虚拟机：通常使用虚拟磁盘文件来存储数据，这些文件可以独立于其他VM进行管理。 Docker容器：使用卷（volumes）和绑定挂载（bind mounts）来持久化数据，这些可以被多个容器共享或独立管理。 总而言之，Docker作为一种轻量级、便捷、高效且快速部署的方法，在云原生应用开发中得到了广泛应用。而虚拟机则仍然适用于需要强隔离、安全要求高以及需要运行不同类型操作系统等场景。\nDocker的核心原理是:\nDocker的核心原理是利用操作系统级的虚拟化技术（即容器化技术）来创建、部署和运行应用程序。具体来说，Docker 的核心原理包括以下几个方面：\nNamespace（命名空间）隔离：\nDocker 使用 Linux 内核的命名空间（Namespace）功能来实现进程隔离。这些命名空间包括 UTS（主机和域名）、IPC（进程间通信）、PID（进程 ID）、Network（网络）、Mount（文件系统挂载点）等。 每个容器都有独立的命名空间，因此它们之间不会互相干扰，提供了类似虚拟机的隔离效果。 Cgroups（控制组）资源控制：\nCgroups 是 Linux 内核提供的一种机制，用于限制、记录和隔离单个进程组的资源使用情况。Docker 使用 Cgroups 来限制容器可以使用的 CPU、内存、磁盘 I/O 等资源。 通过这种方式，Docker 能够确保每个容器在资源分配上互不干扰，并且可以避免某个容器滥用系统资源。 Union File System（联合文件系统）：\nDocker 使用联合文件系统，如 AUFS、OverlayFS 等，来实现镜像和容器的分层存储。每个 Docker 镜像由多层组成，每一层都是只读的，当需要对镜像进行修改时，会在顶层添加一个可写层。 这种分层设计不仅提高了存储效率，还使得镜像可以快速构建和共享。 Container Image（容器镜像）：\n容器镜像是一个包含应用程序及其所有依赖项的只读模板。Docker 容器是从这些镜像创建出来的一种运行实例。 镜像可以通过 Dockerfile 定义，并且支持版本管理，这使得应用程序环境变得可移植且易于复制。 Container Runtime：\nDocker 提供了一个高效的运行时环境，使得容器能够快速启动和停止。 容器运行时负责管理容器生命周期，包括创建、启动、停止和销毁等操作。 Networking and Storage：\nDocker 提供了一整套网络解决方案，使得不同主机上的容器能够通过虚拟网络进行通信。 同时，Docker 也支持将本地存储或分布式存储挂载到容器中，以便持久化数据。 通过这些核心技术，Docker 实现了轻量级、高效、安全的应用程序虚拟化，为开发者提供了一种简便的方法在任何环境中一致地部署应用。\nDocker 里重要的概念是 Image 就是镜像，可以理解为你一个系统镜像。是说明一个容器里怎么执行的。Image 的概念\n是类似于一个模板，它包含了运行应用所需的所有依赖和配置。每个镜像由一系列层次组成，每一层都描述了文件系统的一部分变化。了解镜像的构建和使用，有助于我们更好地管理容器化环境。\n镜像的构建 镜像通常通过 Dockerfile 来定义和构建。Dockerfile 是一个文本文件，其中包含了一系列指令，这些指令定义了如何从基础镜像创建一个新的自定义镜像。例如，常见的 Dockerfile 指令包括：\nFROM：\n指定基础镜像。例如，FROM ubuntu:latest 表示以最新版本的 Ubuntu 镜像为基础。 RUN：\n执行命令。例如，RUN apt-get update \u0026amp;\u0026amp; apt-get install -y nginx 表示在创建镜像时执行更新包索引并安装 Nginx。 COPY 和 ADD：\n将本地文件或目录复制到镜像中。例如，COPY . /app 表示将当前目录下的所有内容复制到镜像中的 /app 目录。 CMD 和 ENTRYPOINT：\n定义容器启动时要执行的命令。例如，CMD [ \u0026quot;nginx\u0026quot;, \u0026quot;-g\u0026quot;, \u0026quot;daemon off;\u0026quot; ] 表示容器启动时运行 Nginx。 镜像仓库 构建好的镜像可以推送到远程仓库（如 Docker Hub 或私有仓库），以便在不同环境中拉取和使用。常用操作包括：\ndocker push: 将本地镜像推送到远程仓库。 docker pull: 从远程仓库拉取指定镜像。 docker tag: 给本地镜像打标签，以便标识不同版本。 容器生命周期管理 容器是基于镜像实例化出来的运行实体。为了高效管理容器生命周期，我们需要掌握以下基本操作：\n启动容器：\n使用 docker run 命令启动新容器，例如 docker run -d --name my-nginx nginx:latest 启动一个名为 my-nginx 的 Nginx 容器。 停止容器：\n使用 docker stop 命令停止正在运行的容器，例如 docker stop my-nginx 停止名为 my-nginx 的容器。 删除容器：\n使用 docker rm 命令删除已停止的容器，例如 docker rm my-nginx 删除名为 my-nginx 的容器。 查看日志：\n使用 docker logs 命令查看指定容器的日志输出，例如 docker logs my-nginx. 进入正在运行的容器：\n使用 docker exec 命令进入正在运行中的某个容器进行调试或维护，例如 docker exec -it my-nginx /bin/bash. 通过对这些操作的熟练掌握，我们可以高效地管理和维护基于 Docker 的应用环境，从而提升开发与运维效率。\nK8s 编排 \u0026amp; 集群 Kubernetes（简称k8s）是一个开源的容器编排平台，用于自动化容器化应用的部署、扩展和管理。它提供了一个统一的平台，使得开发、测试和生产环境中的应用管理变得更加简便和高效。\n核心概念 节点（Node）：\n节点是 Kubernetes 集群中的工作机器，可以是物理机或虚拟机。每个节点上都运行着多个容器，同时也有必要的组件来管理这些容器，包括 kubelet、kube-proxy 等。 Pod：\nPod 是 Kubernetes 中最小的部署单位，一个 Pod 可以包含一个或多个紧密耦合的容器，这些容器共享网络命名空间和存储卷。Pod 通常用于运行单个应用实例或多个协同工作的应用组件。 控制平面（Control Plane）：\n控制平面负责集群的全局决策（如调度）以及检测和响应集群事件（如启动新的 pod）。主要组件包括 kube-apiserver、etcd、kube-scheduler 和 kube-controller-manager 等。 命名空间（Namespace）：\n命名空间用于在同一物理集群内创建多个虚拟集群，提供资源隔离机制。不同团队或项目可以使用独立的命名空间来管理各自的资源，避免互相干扰。 服务（Service）：\n服务是一种抽象，定义了一组逻辑上的 Pod 以及访问这些 Pod 的策略。服务通过标签选择器将请求负载分发给后台的一组 Pod，即使这些 Pod 在不同节点上运行。 控制器（Controller）：\n控制器负责维护系统的期望状态，如 Deployment、ReplicaSet 和 StatefulSet 等。它们通过监控当前状态并将其调整为期望状态来确保系统的一致性和可靠性。 部署与管理 Kubernetes 提供了多种资源对象，用于描述和管理集群中的应用：\nDeployment:\nDeployment 定义了应用程序的描述，包括镜像版本、副本数量等，并负责创建或更新 ReplicaSet 来维持指定数量的 Pod 副本。 ReplicaSet:\nReplicaSet 确保任何时候都有指定数量的 Pod 副本在运行，如果某个 Pod 挂掉，会立即启动新的副本来替代它。 StatefulSet:\nStatefulSet 专门用于有状态应用程序，它能保证每个 Pod 有固定标识，并支持有序部署与扩展。 DaemonSet:\nDaemonSet 确保所有符合条件的节点上都运行一个特定类型的 Pod，例如日志收集代理或监控代理。 Job 和 CronJob:\nJob 用于一次性任务，而 CronJob 则用于周期性任务，两者都确保任务在一定条件下成功执行。 通过理解并灵活运用这些核心概念和资源对象，我们能够实现复杂容器化应用在 Kubernetes 集群上的自动化运维，从而提高系统可靠性与可伸缩性。\n一般 devops 平台上会让用户添加服务，发布服务，服务的 ingress 转发规则配置， 服务的环境变量配置等，展开来讲如下：\n添加服务 在 DevOps 平台上，添加服务通常是指将一个新的应用程序或微服务引入到 Kubernetes 集群中。这个过程通常包括以下步骤：\n定义服务描述文件：\n使用 YAML 或 JSON 格式编写 Kubernetes 服务和部署配置文件。例如，定义一个包含 Deployment 和 Service 的 YAML 文件。 创建命名空间：\n如果需要隔离资源，可以先创建一个新的命名空间。例如，kubectl create namespace my-app。 应用配置文件：\n使用 kubectl apply -f 命令将配置文件应用到集群中。例如，kubectl apply -f my-app-deployment.yaml。 发布服务 发布服务是指将应用程序的更新版本部署到生产环境中。这通常涉及以下步骤：\n构建新镜像：\n在 CI/CD 管道中构建并推送新的 Docker 镜像。例如，使用 docker build 和 docker push 命令。 更新 Deployment 配置：\n修改 Deployment 配置文件中的镜像版本，并重新应用配置。例如，更新 image: my-app:v2.0 并运行 kubectl apply -f my-app-deployment.yaml。 逐步替换 Pod：\nKubernetes 会根据 Deployment 配置滚动更新 Pod，以最小化停机时间。可以通过 kubectl rollout status deployment/my-app 查看更新状态。 Ingress 转发规则配置 Ingress 是一种 API 对象，可以管理外部访问 Kubernetes 服务的方式。通过 Ingress 控制器和规则配置，可以灵活地处理路由和负载均衡：\n创建 Ingress 资源：\n定义 Ingress 资源的 YAML 文件，包括主机名、路径、目标服务等。例如： apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: my-app-ingress namespace: my-app spec: rules: - host: myapp.example.com http: paths: - path: / pathType: Prefix backend: service: name: my-app-service port: number: 80 应用 Ingress 配置：\n使用 kubectl apply -f ingress.yaml 将 Ingress 资源应用到集群中。 验证访问：\n确认域名解析和路由是否正确，通过浏览器或命令行工具（如 curl）访问相应 URL 进行测试。 环境变量配置 在 Kubernetes 中，可以通过 ConfigMap 和 Secret 来管理环境变量：\n创建 ConfigMap 或 Secret：\n定义包含环境变量的 ConfigMap 或 Secret。例如，使用以下命令创建 ConfigMap： kubectl create configmap app-config --from-literal=KEY=value --namespace=my-app 在 Pod 中引用环境变量：\n在 Deployment 配置文件中引用 ConfigMap 或 Secret 环境变量，例如： apiVersion: apps/v1 kind: Deployment metadata: name: my-app-deployment namespace: my-app spec: template: spec: containers: - name: my-container image: my-image:v1.0 envFrom: - configMapRef: name: app-config env: - name: SECRET_KEY # 引用 Secret 环境变量示例 valueFrom: secretKeyRef: name: app-secret key: SECRET_KEY 通过这些步骤，我们可以灵活地管理和发布容器化应用，从而实现高效的 DevOps 流程。\n下面讲一讲 k8s 集群\n的搭建与管理。\nKubernetes 集群的搭建 Kubernetes 集群是由一组工作节点（Node）和控制平面（Control Plane）组件组成。搭建 Kubernetes 集群有多种方法，以下是几种常用的方法：\n使用 Minikube：\nMinikube 是一个单节点的 Kubernetes 集群，非常适合本地开发和测试。通过以下命令可以快速启动一个 Minikube 集群： minikube start 使用 kubeadm：\nkubeadm 是官方提供的工具，用于快速部署生产级别的 Kubernetes 集群。下面是基本步骤： 在所有节点上安装 Docker 和 kubeadm。 在主节点上初始化集群： sudo kubeadm init --pod-network-cidr=10.244.0.0/16 配置 kubectl 命令行工具： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 在工作节点上加入集群（获取 join 命令并在工作节点上运行）。 使用云服务提供商的托管方案：\n各大云服务提供商（如 AWS、GCP、Azure 等）都提供了托管的 Kubernetes 服务，例如 AWS 的 EKS、GCP 的 GKE 和 Azure 的 AKS。这些服务简化了集群管理，用户只需关注应用部署。 管理 Kubernetes 集群 一旦集群搭建完成，我们需要通过各种工具和策略来管理和维护它：\n监控与日志：\n使用 Prometheus 和 Grafana 监控集群状态和应用性能。 使用 Fluentd 或 ELK 堆栈收集和分析日志。 自动伸缩：\n配置 Horizontal Pod Autoscaler (HPA) 根据负载自动调整 Pod 数量。 使用 Cluster Autoscaler 根据资源需求自动调整节点数量。 备份与恢复：\n定期备份 etcd 数据存储，以防止数据丢失。 使用 Velero 等工具进行应用级别备份和恢复。 安全性：\n配置 RBAC（角色权限控制）确保访问控制。 使用网络策略（Network Policies）隔离不同命名空间的流量。 定期扫描镜像漏洞，确保镜像安全。 通过这些步骤，我们可以确保 Kubernetes 集群稳定、高效、安全地运行，从而为容器化应用提供强大的支撑平台。\n","permalink":"https://tomorrowthief.github.io/posts/devops/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003eDevops 从18年左右发展至今已经非常的成熟。可以作为一个独立职业，因为里面有很多细节。作为互联网软件开发者，我从开发的视角梳理下一些应知应会的框架，主要达到一个能使用，能了解架构，出了问题大概知道在哪个环节。具体细节暂时不追求。\u003c/p\u003e","title":"Devops概念梳理"},{"content":"背景 近期工作中做了 LLM 长记忆功能，对此中的思路，技术做下总结。顺便为了练习自己的系统设计能力，这里按照系统设计的方式来整理\n什么是长记忆 简单来说就是让大模型具备记忆功能，记住某个人。产品形态上可以是个人助手。不同于某次会话上下文记忆，长记忆具备的特点：\n跟随个人的：我们目前常见的短期记忆只是跟随某次会话 时间长：1年，5年，10年，……，终生 个人信息相关的：比如个人爱好，心情变化，健康，工作，生活等这些属于个人记忆。客观信息事实信息比如：美国在北美洲，地球是圆的等这些不需要作为记忆信息。 多种类型的：如上条有不同类型的记忆，不同类型的记忆里处理方式有很大差异，比如：日程相关的需要处理时间，绝对时间的转换，个人爱好相关的，比较简单，直接用类似图谱的三元组信息即可，办公工作内容型的记忆类似。 功能点及非功能点梳理 总体其实为了实现个人助手的产品功能。这个助手在产品形态上是一个普通对话机器人，系统的具备的功能及非功能点需求大致如下：\n功能点 登录，因为是私人助手嘛，得知道用户是谁。 对话：这个不用说了，是助手的主题功能 配置功能，因为记忆有很多种类型，在助手里最好有配置，比如我想主要是工作，那日程安排比较重要，生活。如果多有记忆都要配置，那就是一个超级个人助手 记忆生产：根据配置信息，做不同类型的记忆提取存储 记忆消费：是指根据记忆：做下健康管理，饮食管理，工作学习计划，日程计划，等等。 非功能点 短期能同时处理 1w+ 人数的并发，长期的话人数可能扩充到 10W+，甚至更多。每天可能有 50W 的请求 响应时间：在记忆消费时能做到 3s - 5s 内有响应，3s-30s 内响应完成。 数据规模，根据每个人的配置，记忆长短不同，数据规模有不同要求 方案 工作流程图\n如图所示。总体为一个 RAG 流程，其中核心是记忆引擎的部分。由于rag流程基础的东西，在社区里做的比较多，也比较简单，不做过多强调。核心强调记忆引擎的东西。\n记忆引擎 记忆引擎里完成的功能：\n记忆生产 根据配置信息生产一些垂类记忆 记忆存储 把记忆抽出来后 记忆消费 根据用户的问题，召回相关的记忆，并做简单推理规划 记忆生产 这里输入是会话信息，需要做的是从会话信息里提取记忆实体。主要涉及到自然语言处理的部分。 知识图谱，我们使用知识图谱来完成记忆的载体。\n知识图谱的实体抽取，以及图数据库语法都是用额外的大模型来推理完成\n提示词设计 // 信息抽取 ` 你是一个信息提取专家 用户的输入如下：{query} 实体信息： ` // 记忆更新 ` 你是一个图数据专家，请生成neo4j的sql语句 历史记忆如下：{memories} 新的记忆如下：{memory} sql: ` 这里只给出部分，因为其他一些垂类的内容。其他还有很多，也算是核心。\n记忆消费 这里就是拼装提示词，召回后相关信息，做一下记忆拼接，最终的提示词\n大概如下\n`历史记忆如下: {memories} 问题: {query} ` 把记忆引擎抽离出来一个独立服务 这个记忆引擎可以抽你出来一个独立服务，给其他提供服务。\n未来如果有类人机器人出现，这个引擎可以作为其大脑的一部分。\n小节 本质上记忆引擎里的核心还是提示词，属于是：用大模型本身去解决大模型的问题。是不是有点类似于：我不是要你的钱，我只是拿你的钱办你的事。和珅表示这事我熟悉\n技术选型 后端：Python FastApi 存储：图数据库，向量数据库，Postgresql 前端：React Nextjs\n未来规划 交互上更加拟人一些，比如加入 tts，以及 stt\n社区方案 mem0 我在实践过程中严重依赖了这个方案，不得不说社区力量还是强大\n总结 在实际中体验下来，最终方案已经基本能用。提交给产品后，收获到了一些正向反馈。目前这个产品可以定位为超级个人助理。可以配置记忆倾向点，也可以手动录入一些记忆信息，以及一些非结构化的记忆。\n方案思路很简单，调优巨复杂。做过的估计都有体会，这也是现阶段很多AI应用的通用问题。所以会涌现出很多奇淫巧技让这些效果变好，或许这就是技术存在的意义吧：在有限的条件下尽量产生价值\n方案上还是会演进的，因为目前总体上还是提示词工程的玩法。这种模式会受到大模型本身技术发展影响的。大模型的窗口，推理精读都会影响我们的方案设计。\nAny Way 无论如何。在 AI 时代下，此类产品会越来越多，我们一定要利用好这些产品来辅助提升我们的效率。让我们自己变成超级个体，一个人相当于一个团队。\n","permalink":"https://tomorrowthief.github.io/posts/ai-longterm-memory/","summary":"\u003ch1 id=\"背景\"\u003e背景\u003c/h1\u003e\n\u003cp\u003e近期工作中做了 LLM 长记忆功能，对此中的思路，技术做下总结。顺便为了练习自己的系统设计能力，这里按照系统设计的方式来整理\u003c/p\u003e\n\u003ch2 id=\"什么是长记忆\"\u003e什么是长记忆\u003c/h2\u003e\n\u003cp\u003e简单来说就是让大模型具备记忆功能，记住某个人。产品形态上可以是个人助手。不同于某次会话上下文记忆，长记忆具备的特点：\u003c/p\u003e","title":"LLM 长记忆工具总结"},{"content":"背景 做了大半年左右的后端开发后，总结下相关感受。\n技术栈：Python/Nodejs + React\n行业背景：LLM 应用， RAG， Agent\n后端开发思路 后端关注面更广范，几乎要关注整个应用软件运行所需所有的环节： 运维，应用，业务，服务，UI 等。\n其中核心工作流在于：充分理解需求，转换业务需求到系统的功能性设计及非功能指标设计。\n功能设计上主要关注：数据结构，类包，业务模块，工作流等 非功能性关注：性能，并发，安全，稳定等 玩的是数据 数据算是核心中的核心了。所有的业务基础都是按照这个来的\n关系型业务 mysql 或者 pg，选一个吧，这里我还没遇到两者特别大的差异的地方，因为我的业务场景里没那么复杂\n这里主要考虑：表结构设计，索引设计。\n如果到一定规模考虑 分区，分表，分库\n实际业务中大多需要找一个 ORM 库来完成在应用里方便的操作。\n如果有 Redis 或者其他异步复杂的事务处理，需要进一步考虑数据一致性。\n非关系 Redis，Es，Mongodb，图数据库\n日志相关的一般存放到 mongodb 或者es，由于他们在倒排索引的效果做的比较好，方便快速全文索引，海量存储。\nRedis：内存数据库，来缓解在 mysql里不经常变动，又频繁查询的操作压力。当然他也可以做一些简单的消息中间件等\n图数据库\n在一些场景里需要做知识图谱，做关系，图数据库特别适合。这里核心是实体关系等三元组信息抽取，已有知识更新。得益于大模型这个第二大脑的配合，可以通过提示词让LLM帮我们去做实体抽取，三元组信息变得简单很多\n小结 这块也是一个非常大的技术体系，往深走的话需要专题讨论。\n我这边是入门不久，着重看了 Mysql 执行引擎的内容，B+ 索引的来由。练习了常用 SQL 语法（leetcode 50高频sql）\n由于之前了解过大数据基础知识，所以对于我前端出身学习这块，难度不大。\n一些中间件 消息中间件 几乎是必须的，做异步，服务结构等 任务队列 做性能，并发等 日志，错误处理等 微服务体系 很多公司其他基础模块都是基于微服务的方式提供的。系统扩充到一定程度肯定少不了微服务架构的梳理\n得益于 Service Mesh 这种微服务2.0架构。做上层应用变得异常简单了。日志，监控，服务注册调用 等都在 SideCar里\n我之前有过 Nodejs 接入微服务体系的经验，所以这块难度也不是特比大\n计算机基础 计算机组成：cpu，gpu，硬盘，内存 操作系统：进程线程协程等，资源管理，IO管理：网络/文件 编译：前端：分词，语法分析，语法树，后端：机器平台生成 分布式-时间空间互换 这里我觉得是计算机性能上一个很重要的思路，在优先的单机资源下实现高复杂度计算的模式。大数据的基石 Hadoop也是这个核心思想。\n核心竞争力 以前端为主要工作内容体系下，为什么要突破下后端开发的能力？\n生存需要：前端技术发展到一定程度，除非是往某个领域特定发展，但是很容易变成屠龙之术。 我认为市场上需求, 复杂度大多还是后端 即便作为独立开发者也需要后端更多 本来技术上就不存在什么前端，后端，或者其他端。本来的角色应该是软件开发者，问题解决者存在 一切都在变，你敢不变？ 当前AI大背景下，学习新知识，突破边界变得非常简单 所以当前这个环境，我的核心竞争力在于：强悍的工程能力，基于此的问题解决能力，基于此的产品运营的敏锐度\n总结 在 AI 时代软件开发者可以很高效切换一些技术栈，但是一些基础的理论一定要掌握好，否则 ai 可能会把我们带歪。这些基础理论包括：计算机组成，计算机运行原理，现代操作系统，算法。还有就是上文里提出来的工程能力\n最后我的观点是：不要过分在某个点上较真，能够达到自己的目标就是好的。\n可以不屠龙，但是不能不掌握屠龙术\n","permalink":"https://tomorrowthief.github.io/posts/ai-backend-dev/","summary":"\u003ch1 id=\"背景\"\u003e背景\u003c/h1\u003e\n\u003cp\u003e做了大半年左右的后端开发后，总结下相关感受。\u003c/p\u003e\n\u003cp\u003e技术栈：Python/Nodejs + React\u003c/p\u003e\n\u003cp\u003e行业背景：LLM 应用， RAG， Agent\u003c/p\u003e\n\u003ch2 id=\"后端开发思路\"\u003e后端开发思路\u003c/h2\u003e\n\u003cp\u003e后端关注面更广范，几乎要关注整个应用软件运行所需所有的环节： 运维，应用，业务，服务，UI 等。\u003c/p\u003e","title":"后端开发经验-阶段性总结思考"},{"content":" 林语堂苏东坡读后感\n进入偶然原因看了些苏词，同时也看了林语堂的苏轼传，这里记录下所感，所想。重点不是描述豪放的苏词，而是苏轼这种人才的优点，缺点。苏轼若是在当代社会又是咋样的？\n大概过下「苏轼传」 苏轼传记有很多，各种角度去描写的，我选择了林语堂的这本。林语堂是民国时期著名文科生，特点中外双休，说来奇怪，他写的苏轼传是用英语写的，或许是为了向世界科普这个中国巨星。而我读的却是一个国人的译本。既然是面向世界的，选择的角度肯定不太一样了，也会拿西方的文豪大家与苏轼对比。\n这本书里不像一些其他书，用很多首苏词来作为切入点，描写。他直接以苏轼的视角，按照时间线，穿插一些中间人物大事记（弟弟苏澈，伯乐欧阳修，政敌王安石，他的三任夫人，等等），来完成的，也加了不少北宋的政治经济背景，各个皇帝的特点等。所以读下来就是一个北宋中后期的国家命脉缩略。\n不止于诗词 苏轼写词，写诗，是他的立命之本。他的年代是文学的时代，家族里也有好的基因，氛围。他叔已经是当官的，他爸虽然无官，但是唐宋八大家之一，他爸的六国论，他妈的思想已经不是普通妇人的思想了。\n如此的家境放到现在，如果不是特别不着调，抬也能给抬到一个合适的位置。况且他和弟弟在立命之学的年纪里一起下了重功夫，使得他基础太扎实了，所有文字创作信手拈来。任何行业都需要一个扎实的基本功，才能有上层轻松的创作，作家，歌手，程序员，运动员，哪个不是呢?\n他呢，让人津津乐道的不止于诗词。乐天派，豪放派的作风。到哪里都有朋友。喜爱喝酒。也会接触名妓。说到这里，我是觉得不能单纯看他的这些特点，结合他背景：少年成才，国家顶级人才，得到皇帝的大力认可，可谓前途无量。体验过生而为人的巅峰，这个自信自然养成了，也早已脱离了为生计奔波的烦恼。所以即便有在政治斗争里的一贬再贬再再贬，那都不是事。\n林语堂描写他的政论也是一流的，这个是位难得，宋朝不缺文学，但是文学和政论都很好的就少了，范仲淹，欧阳修，司马光，王安石都算是，苏轼当然也算，他的特点似乎是更接地气，更是站在底层大众这一侧。实事求是，真正做事的人。\n他对生活很热爱，对细节观察也很到位，体现在诗词里，也体现在他的书法与国画里，他是南方国画鼻祖。国画里对动物的传神，对山水天人合一的追求，要求作者必须对细节观察做到细致入微。\n能跟任何人玩到一起 书里一个章节：和尚，酒与名妓，来形容他的爱好，形容的真好。他结交了很多僧人，与他们聊思想，交换灵魂。或许这点也是构成他性格的重要瓦片。他朋友圈里很多都是追随他的，比如苏门四学士等。\n皇帝点过他的名，嫉妒者们对他一再打压，太后出于女人第六感，认为他是一个可靠之才，恢复他的官位。他有很多酒友每到一个地方，都不缺朋友，分布到各阶层里。\n他与头号政敌王安石，最后也能畅谈下想法。\n他也是一个普通人 本质上他也是追求名利，没有得到的时候也会迷茫，有了机会的时候也会努力抓住的。在遇到乌台诗案的时候，他也是慌不知所措，内心是恐惧的，害怕死亡，更害怕家人受到牵连。\n作为一个动物，他也是爱好吃喝的。人生中后期也追求长生不老之术，每次被贬也都带了很多家人一起，这点来看条件已经不错了，比起当时草民生活上强了太多。\n也正是一个普通人的特点，才愿意被更多人追随吧，才能被千年后的我们依然喜欢。\n再无苏轼 一个现代社会里很难再出现苏轼这样的人了。首先培养出这样的人才需要巨大的精力，其次在阶层固化，大众追求的理想已经很难到达苏轼这种高度了。于我们苏轼的故事当作聊天语料，当作精神参考，其作品当作我们引经据典的素材，足以。\n","permalink":"https://tomorrowthief.github.io/posts/sudongpo/","summary":"\u003cblockquote\u003e\n\u003cp\u003e林语堂苏东坡读后感\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e进入偶然原因看了些苏词，同时也看了林语堂的苏轼传，这里记录下所感，所想。重点不是描述豪放的苏词，而是苏轼这种人才的优点，缺点。苏轼若是在当代社会又是咋样的？\u003c/p\u003e","title":"苏东坡"},{"content":"为什么要学 Python 最近开始接触 Ai 相关的东西。主要是应用层的内容，比如 RAG Agent 等。此类应用特点：无需太多安全性能，偏向于工具，这块技术发展变化比较迅速，大模型日新月异，应用层技术也跟随变化较多。\n根据此特点选择脚本类型语言作为应用层开发语言。待选语言有 Nodejs python。 个人虽熟悉 Nodejs，但鉴于 Python 生态较好 性能较好等，最后决定 Python。\nPython 综述 Python 第一版本发布于 2000年，目前在 Tiobe 排行榜里人数排名第一，社区热度也升为第一。\n定位：高级语言，通用能力编程语言 特性：动态语言，基于解释器，gc 等 范式：函数编程，面向对象，面向过程 主要在 数据处理，计算，Web等发挥作用，AI 领域使用很多， Web 开发也有很多场景\n运行模式支持 多进程，多线程，协程\n执行流程 这一章直接问了 gpt，下面都是 ai 的回答\n在Python中，程序的执行流程通常是按照以下步骤进行的：\n解释器读取源代码：Python解释器会逐行读取源代码文件，并将其转换为字节码形式，这是一种中间表示形式，可以被Python虚拟机执行。\n词法分析和语法分析：在这个阶段，Python解释器会将源代码分解成单词（Token）并构建语法树。这个过程包括词法分析（将源代码分解为Token）和语法分析（根据语法规则构建语法树）。\n编译字节码：Python解释器将语法树转换为字节码。字节码是一种中间形式，类似于机器码，但是不是针对特定的硬件架构。\n执行字节码：Python虚拟机执行字节码指令。这些指令会被逐条执行，从而实现程序的逻辑。\n动态类型检查：Python是一种动态类型语言，因此在运行时会进行类型检查。如果类型不匹配，会引发类型错误。\n垃圾回收：Python具有自动内存管理机制，包括垃圾回收。垃圾回收器会定期检查不再使用的内存对象，并释放它们。\n异常处理：在程序执行过程中，如果发生异常，Python会查找合适的异常处理程序。如果找不到合适的处理程序，程序会中止并打印错误信息。\n程序结束：当程序执行完所有的代码或遇到显式的退出语句（如return或sys.exit()）时，程序结束执行。\n全局解释性锁 比较独特的一个特性。是 Cpython 里保证同一时刻只能有一个线程来执行字节码，很明显这个单线程是并发的模型，而非并行模型。\n缺点：很明显不能做并行，多核心硬件优势难以体现 优点：线程安全，内存安全（似乎只对 cpython 团队友好，对那些用 c 写库的友好）\n异步编程 Python里的异步编程也经历过一些迭代，基础上是基于时间循环的协程操作。早期用gevent，现在也有很多在用，当下内置模块 asyncio 也实现了相关的封装，可以更加方便的定义异步任务，执行异步任务。\n相比我比较熟悉的 Javascript 里浏览器和 Nodejs 运行时的模式，Python多少还是有点不同： Js 语言里都是默认开启异步的，因为在 js 引擎执行开始就启动了事件循环，而Python不同，需要手动的去开启事件循环来启动异步操作。从这个角度来看，Python 提供了很多底层的 API，让使用者灵活的控制。好处是可以更灵活，性能上更好些，坏处是需要很多底层知识来支撑，否则用不好的话，反倒影响性能\n基本概念 事件循环：管理和调度异步任务的核心组件。 协程：使用 async def 定义的函数，可以在事件循环中异步运行。 任务：由事件循环调度的协程对象。 Future：表示一个异步操作的最终结果，类似于 JavaScript 中的 Promise。 示例 以下是一个简单的示例，展示了如何使用 asyncio 模块来创建和运行事件循环：\nimport asyncio async def say_hello(): print(\u0026#39;Hello\u0026#39;) await asyncio.sleep(1) print(\u0026#39;World\u0026#39;) async def main(): await asyncio.gather(say_hello(), say_hello()) # 获取默认事件循环并运行主协程 asyncio.run(main()) 解释 定义协程：使用 async def 定义了一个名为 say_hello 的协程，它在打印 Hello 后等待 1 秒，然后打印 World。 主协程：定义了一个名为 main 的协程，它使用 asyncio.gather 并发地运行两个 say_hello 协程。 运行事件循环：使用 asyncio.run 获取默认事件循环并运行 main 协程。 事件循环的工作原理 启动事件循环：当调用 asyncio.run(main()) 时，事件循环启动并开始运行 main 协程。 调度任务：事件循环调度 main 协程中的任务。在这个例子中，asyncio.gather 会并发地运行两个 say_hello 协程。 处理 I/O 操作：当协程遇到 I/O 操作（如 await asyncio.sleep(1)），事件循环会挂起该协程并切换到其他可运行的任务。 完成任务：当 I/O 操作完成时，事件循环会恢复被挂起的协程并继续执行。 结束事件循环：当所有任务完成时，事件循环停止。 更复杂的示例 以下是一个更复杂的示例，展示了如何处理多个异步任务和超时：\nimport asyncio async def fetch_data(delay, name): print(f\u0026#39;Starting {name}\u0026#39;) await asyncio.sleep(delay) print(f\u0026#39;Finished {name}\u0026#39;) async def main(): task1 = asyncio.create_task(fetch_data(2, \u0026#39;Task 1\u0026#39;)) task2 = asyncio.create_task(fetch_data(3, \u0026#39;Task 2\u0026#39;)) task3 = asyncio.create_task(fetch_data(1, \u0026#39;Task 3\u0026#39;)) await asyncio.wait([task1, task2, task3], timeout=2.5) # 运行事件循环 asyncio.run(main()) 解释 创建任务：使用 asyncio.create_task 创建了三个任务，每个任务在不同的延迟后完成。 等待任务：使用 asyncio.wait 并设置超时时间为 2.5 秒。如果某些任务在超时时间内未完成，它们将被取消。 输出结果 Starting Task 1 Starting Task 2 Starting Task 3 Finished Task 3 Finished Task 1 在这个例子中，Task 2 因为超时而未能完成。\n处理超时 如果你需要处理超时，可以使用 asyncio.TimeoutError：\nasync def main(): try: await asyncio.wait_for(fetch_data(3, \u0026#39;Task 2\u0026#39;), timeout=2) except asyncio.TimeoutError: print(\u0026#39;Task 2 timed out\u0026#39;) asyncio.run(main()) 本章小节 Python 的 asyncio 模块提供了强大的工具来编写高效的异步 I/O 代码。通过理解事件循环、协程和任务的工作原理，可以更好地编写和调试异步 Python 程序。\n比较有意思的是， Javascript 里并没有提供事件循环的底层 API，而 Python 却提供了很多。从这点来看Python灵活性更好，在需要充分榨干 cpu 的场景中会有更好的表现，就像 C++ 提供了垃圾回收的低层级API，而 Java 则直接用Jvm 的 gc 机制来做，使得 c++ 性能更强，更灵活, 当然编写难度也会提升，实际技术选型时要综合考虑。\n本章多列举了一些案例，因为我觉得大部分场景都会用到异步编程，而需要进程模型相关的一般交给其他语言处理了\n并发控制 支持进程模型，线程模型 有原生的线程池对象 有队列的原生对象 协程信号量等 语法 使用缩进来表示一些行为\n非常灵活，以至于我现在还是新手。\n魔法函数 通过魔法函数机制让语言使用者可以做很多元编程的事情：修改默认行为。\ninit getitem …… 需要的话直接翻阅手册吧 记忆深刻的语法 列表推导 函数变量：位置变量，关键字变量 小括号很少 数组各种切片，数组相加 优秀框架库 Web服务开发： Flask FastAPI 任务队列： Celery 很多 Agent 数据开发相关: Panda Numpy 深度学习： PyTorch Tenserflow 图数据库： Neo4j 工具 包管理：不得不说python的这块挺混乱的，有 pip，pipx，poetry 等。我现在使用 uv + venv。感觉很爽\n代码格式类型检测：ruff\n社区关注 会关注社区里的 Python core dev 成员。其中有一个是中国人：高天，在 B站 上看过他不少视频，讲的都是比较基础的，比较内核的。\n总结 入门比较容易。本文内容主要是我在做两个项目中 学习到的一些概念，知识点。感觉目前能成为一个中级开发了。如果后面用了一些其他高级功能，再专题写一下具体的部分\n到了一定程度语言已经不是问题的关键了，怎么熟悉整个技术体系更重要，比如在Web服务开发领域：计算机组成，操组系统，编译原理，等基础概念，数据库，高并发，分布式这些架构。\n","permalink":"https://tomorrowthief.github.io/posts/ai-python/","summary":"\u003ch2 id=\"为什么要学-python\"\u003e为什么要学 Python\u003c/h2\u003e\n\u003cp\u003e最近开始接触 Ai 相关的东西。主要是应用层的内容，比如 RAG Agent 等。此类应用特点：无需太多安全性能，偏向于工具，这块技术发展变化比较迅速，大模型日新月异，应用层技术也跟随变化较多。\u003c/p\u003e","title":"Python 学习总结"},{"content":"近两年AI太火了，认真体验及分析后, 决定尽量跟上, 最少要把相关工具使用好。恰好工作中也在做相关工具，遂梳理之, 以加深对这块的理解。\n打败马车夫的不是汽车本身，而是会开车的司机\n生成式AI的爆发 AI 这个领域很早就开始了，这个理念也很早就有了，比如早期图像处理，语音识别，阿尔法go等。可以回溯之前很多年。为何最近两年开始爆火了。我认为原因有几点：\n技术突破: 大模型的底层基于神经网络的深度学习推出了 transformer 架构。改变了大模型深度学习的格局带来了质的飞跃 基础设施发展: 一个模型巨量的计算，消耗大量资源。硬件基础设施的发展能降低训练成本，试错成本，让更多想法去实现 数据的积累: 互联网发展至今产生了大量数据，可以作为训练知识来让模型学习，这些都是人类发展产生的财富。 简单说下 Transformer 最早是在论文 Attention is all you need 提出注意力的机，以解决在序列生成中，长序列情况下的精度，简单一点来说是通过空间位置编码，扩充之前神经网络里的一些信息，使得即使再有更多长度，也不会让精度下降。\n现代架构里添加了很多其他模块：比如多头自注意力机制，并行机制等。\n总之结果是：推理精读更好，训练效率更高。这是当今 AIGC 爆发的技术基础\n能改变什么 有人说任何行业都可以重新再做一遍\n人类的进步，从来离不开工具，有了轮子就有了车，马车，有了蒸汽机就有了汽车，这些都是革命性的改进，都是依赖工具的。工具改变了生产力，进一步质变为影响生产关系。促进了社会整体变化。\n总结下来当前影响最大的几个面：\n广告/自媒体行业的商业模式 剪辑，修图，这种体力活完全可以用AI帮忙做了\n教育教培，学习方式 对于家长可以用 AI 辅助教养小孩子，学生也可以方便的用AI自助学习。\n工作效率提升 有些细节直接用AI生成即可，员工负责更高一层的控制\n软件开发程序员 我本身就在程序员行当里，对这个提效深有体会\n局限性 正如人类能想象到的东西都是现有认知范围内现有知识体系内的东西一样，AI 学习能力目前还处于理解现有知识体系的状态。无法突破知识界限，只有在有限的知识范围内做一个最强大脑。 所以局限性在于，他只是一个只能基于现有知识的超强大脑，无法升维无法突破边界。 当然如果有了一个这样超强大脑，本身就是一件很厉害的事情。至于突破编辑，升维知识，这个还要考我们人类，然后再喂给AI，形成一个循环。\n一旦AI具备 公理，定律等级别的创新，是非常恐怖的，人类的一切迷惑将不再是迷惑，我是谁？来自哪里？要去哪里？上帝是谁，造物主是谁，各方神灵，神明又是谁？宇宙之外在哪里？生命是什么？为什么活着，为啥又要死去\n模型 百花齐放，百家争鸣。通用，垂类，领域模型等太多了，发展过于迅速，具体模型此处不多谈。\n要谈的是：\n深度学习模式的变革，基于 Transformer 架构的深度学习促进了当下模型厂商的发展，多层 Transformer 架构使得大模型更像人类大脑。 向量化，万事万物皆是向量，皆是数据，向量这个结构让事物之间的关系拉平了。就像分子，化学元素一样，构成了物质世界，而向量则在虚拟世界里描述这个世界 基于这两个重要的底层知识，模型的发展，飞起来了。\n菩提本无树，明镜亦非台，本来无一物，何处惹尘埃\nAI应用 大模型还毕竟只是一个最强大脑，一个超强CPU。我们知道通用计算机，不止CPU，还有一些外围设备才能通用工作，人类也是，不止大脑，还有眼睛，手，等外围设备。\n所以 AI 应用，或则 Agent 的概念，可以如此类比。\n技术工具 开源的技术工具很多，目前我在用 Langchain。但是不能局限于这些上层工具\n他是一把双刃剑 一把剑在高手手中，就是如虎添翼，在一个低手里，甚至可能会伤害到自己。\n截止目前，AI 工具依然如此。自身素质的提升，才能将这个工具发挥到巨大的价值，否则可能被带入的错误的方向。\n我在做什么 我在做 AI 应用， AI Agent。让大模型这个最强大脑扩展一些外围设备，让他更像人类一样，某种意义上来说也是一种AGI的探索。\n生活上，要考虑这些新的东西，能不能给自己带来切身收获，直白一点怎么变现，怎么让他提升自己的核心竞争力，在这承平已久，开始出现混乱的年代里，怎么用这个活下去。\n","permalink":"https://tomorrowthief.github.io/posts/ai-work-thought/","summary":"\u003cp\u003e近两年AI太火了，认真体验及分析后, 决定尽量跟上, 最少要把相关工具使用好。恰好工作中也在做相关工具，遂梳理之, 以加深对这块的理解。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e打败马车夫的不是汽车本身，而是会开车的司机\u003c/p\u003e","title":"AI应用实践的思考"},{"content":"此为一种劝诫训子的书，主要方向是如何处事，也可以是一本养心之书。从中国传统价值观及儒释道的哲学体系来讲述如何处事。总体分为四部分。\n作者是明万历期，69岁时所著。推荐此书的名人：曾国藩，据说其号 涤生 就是因为此书而来；稻盛和夫等。\n阅读建议：作为枕边书，或者心静的时候细读。\n分篇章总结 立命之学 此为开篇，作者以自己早起人生经历，讲述处事流程中第一个阶段：立命。非常重要的人生阶段，大概人与人的差距也会在此拉开。\n我命由我不由天 本篇最重要的概念了算是。具体一点就是命运是自己把握的。这一点估计现代人看到后会有很多反对点：起跑线不一样，人生结局可大大不同了。\n我的理解是：天生给到的东西已成定行，无法改变。但是之后的情形，还需通过自身不断学习，不断发展来改变。我们尽量做好能做的，其他的只能坦然接受。\n弃医从文 改变医生的方向，发展仕途的方向。中国历来都是学而优则仕，其他都是歧途。当下路子多了起来，但是遇到环境恶略的时候，发现还得是公务员稳啊。\n持续学习 文中讲到：顺利时也不要忘记努力发展，说不定啥时候不顺就来了。跟当下持续学习的概念不谋而合。随时准备拥抱变化，唯有持续学习，持续适应才能得心应手。\n不念过往 从前种种譬如昨日死，往后种种譬如今日生。\n改过之法 内心，真心，是前提。我觉得这一篇是重要紧急四象限的第二象限里的东西，很重要，也很容易忽略而没做好，应该是我们每天首要考虑的东西\n先有耻辱感 是否曲直，做一个有原则的人\n发自内心的行动 是否是真的在做，还是在模仿，还是在做一个样子。改过之行，来不得半点虚伪。\n积善之方 这一篇里讲述了要行善，行什么善，从十种角度来分析 善，区别什么是善，如何下后。此篇结构简单，但是内容较多，可以选择行阅读\n但行好事莫问前程 这一篇是很佛教里的思想了，善有善报恶有恶报。我不敢苟同这个观点，现实遇到太多事情违背这个理论了。\n但是我觉得行善还是有必要做的。并不是为了有善报，也不会因为你行了善就会有善报。最起码不要去做恶吧，能有一份心安理得不就够了么？\n不平等的地方太多了 社会上不平等的地方很多。若你可能是占便宜的一方，你会怎么想，而你是吃亏的一方，你又怎么想？\n做事情不可太功利 太过于功利，可能会变形。读一本书就想获得人生智慧，学一个技能就想发财致富，别想了。\n谦德之效 为人要低调的方式。不要轻易显山露水，少说话多干事。勿要恃才傲物，做事抱有空杯心态，虚怀若谷。\n总结 这本书，于我作为一本修心的书去阅读。对于有些人会问值不值得读，我觉得非常值得。但书和道理是死的。看你怎么理解消化了。\n从前种种, 譬如昨日死; 以后种种, 譬如今日生.\n","permalink":"https://tomorrowthief.github.io/posts/liaofansixun/","summary":"\u003cp\u003e此为一种劝诫训子的书，主要方向是如何处事，也可以是一本养心之书。从中国传统价值观及儒释道的哲学体系来讲述如何处事。总体分为四部分。\u003c/p\u003e\n\u003cp\u003e作者是明万历期，69岁时所著。推荐此书的名人：曾国藩，据说其号 \u003ccode\u003e涤生\u003c/code\u003e 就是因为此书而来；稻盛和夫等。\u003c/p\u003e","title":"了凡四训"},{"content":" 六国破灭非并不利战不善，弊在赂秦……\n近日偶然重新看了这篇文章。再细读后，才发现其文风犀利，逻辑清晰，论点简明有力。虽作为高中时期的教材，那会儿跟不懂内容只知道背诵那些文字，再读后有种相见恨晚的感觉。\n全文读下来感觉朗朗上口，思路清晰，逻辑感也很强。是一篇非常好的议论文。\n一些文段 今日割五城，明日割十城，然后换得一夕安寝。起视四境，而秦兵又至。\n用物质消灭贪婪是不可能的，犹抱薪救火，薪不尽火不灭。讲的是人的贪婪欲望是无限的，一味的去迎合这些，那就会陷入无底洞。\n以赂秦之地封天下之谋臣，以事秦之心礼天下奇才，并力向西。则吾恐秦人食之不得下咽也\n这里想到了一个公司内耗严重的时候，将这些内耗的精力拿到做应该做的事情，才是公司团队应该的做法。\n个体利益与群体利益 上面那个道理我想很多人都会懂，但是为什么现实中还是会陷入内耗中。我觉得是一些人性本质问题: 为什么要你过的比我好，我玩不了，大家也都别想玩，所谓不患寡而患不均。另外就是在总的资源有限人又很多的时候，每个人都为了生存不得选择了个体利益优先的决定。\n这种能做到全局最佳解的方式，目前只发现了蚂蚁，蜜蜂这些动物群体做好。一方面因为这些动物单个个体是没有思想的，生来机械的负责一些事情。而人类是有思想的有感情的，在这些生存决策前往往会选择只符合单一个体利益的情况。\n六国论里这个观点在理性上是全局最合理的，但是考虑到现实中人的本性问题，每个国家都有各自的想法，思想。最终的决策往往是不合乎理性的。\n所以我觉得六国破灭的另一个深层次的因素是人性本质问题，而要解决这个问题需要合。要有个唯一负责人来调度各国，形成统一战力\n公司里的六国 公司内部各个部门众多，单个部门想推动全局做好一件事情是比较困难的，这里最好通过一个总指挥的制度去推进事情。然而事实中关系错中复杂，身处此中的你我大多选择苟活，如此跟六国中的赂秦战术并无大的区别\n","permalink":"https://tomorrowthief.github.io/posts/liuguolun/","summary":"\u003cblockquote\u003e\n\u003cp\u003e六国破灭非并不利战不善，弊在赂秦……\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e近日偶然重新看了这篇文章。再细读后，才发现其文风犀利，逻辑清晰，论点简明有力。虽作为高中时期的教材，那会儿跟不懂内容只知道背诵那些文字，再读后有种相见恨晚的感觉。\u003c/p\u003e","title":"再读六国论"},{"content":"前言 近日工作不忙，偶然看到孙子兵法一书，印象里面应是各种打打杀杀，由无他事就读了一些，发现并不是那么简单。 博主在上下班路上，前后半个月的时间学习了一些。为了加深自己的记忆，理解。就梳理了这篇札记\n孙子兵法 是什么 孙子兵法是一本信息熵极高的阐述战争方法论的书，原文仅 6000 余字。经过之后两千多年时间沉淀：注解引申，国内外各大名家的参与，现在已经形成了一个战争理论生态，战争方法论。这里说的战争可以是冷兵器时代的战争，也可以是强调技术装备，信息化的现在战争，也可以是商战，工作职场，学业，投资。现在已经翻译了多国语言，据说在国外也比较流行，认可度极高。\n适读人群: 最好是有一定工作生活经验的人，如果是单纯的学生不建议阅读\n架构图 注此图引自知乎\n首先-不去战争 孙子兵法首要强调的是不战而胜，因为战争成本太高代价太大。特等医生的价值不是体现在治病救人，而是在生病前防疫工作：如何不得病，如何尽早发现病并及时治理。当然这里不是贬低治病救人的技术，只是我们经常忽略准备防疫的重要性，到了生病时候才发现代价真的太大。所以孙子兵法虽然是一本兵书，却比较强调怎么不去战争，规避战争，强调的是：日积月累，有备无患\n作战原则 实际中战斗是不可避免的。如何做好呢？战斗就像做事做人。孙子兵法全文里强调三大原则：知己知彼, 先胜后站, 至人而不至于人。很多具体章节里都是为了满足遵循这几个原则的，所以理解透了这些原则思想，一切满足此的都可以称为好兵法。\n就像软件架构里的设计模式 solid 原则，很多具体的模式都是为了满足实现solid原则。这些原则是贯穿整体的\n工作中需要做参考别的技术，大多是学习了别人的思想，别人的原则，然后根据自己的情况实现一套可行的方案。\n基本面 战前准备的方法论：五事七计(具体看上面架构图)。运筹帷幄，庙堂之上充分分析各个因素，最后制定出最有利的战斗计划。\n如同我们在做编码设计，或则项目时，基本都是先尽可能做好详设计，而这些又是比较耗费精力的。最后写代码具体工作却是很快的。倘若设计阶段没做好，后面很可能比较被动，代码自量也难以保证，返工之类的。\n操作面 有了五十七计，胜负因素方向已定。而战场却又千变万化，影响因素也不计其数。就要因地制宜的去发挥。孙子兵法里提出有行军，九地九变等，都是讲一些具体情况下的做法。\n这里我理解我们工作尤其是互联网这种变化较多工作，必须要做好抬头看路的工作。把握政策情况，市场情况，个人成长情况然后做好自己的规划。\n个人收获 收获还是挺多：明确了做事的 原则，系统分析法所谓方法论，底层逻辑。以及该做哪些事情，不该做哪些事情的取舍\n不要忽略基本面 善战者,无智名,无勇功。\n人们往往比较喜欢波澜壮阔的故事，而忽略基本面的作用。比如我们喜欢韩信背水一战的故事，但是从理论来上看是违背 五事七计 的分析。诸葛亮出师北伐的例子也是在基本面上就输了，汉武大帝的传奇一生，却耗费了文景之治的积累，所谓一将功成万骨枯。\n古今中外精彩故事也不少，但那是2000多年的历史积累，更多的是默默无闻却又贡献很多的平淡故事\n我们每个人也一样，绝大多数都是平凡平淡的。但是能把基础面做好，有一份好的学业，经营一份自己的工作事业，有个好的身体健康素质，已经能达到生活的意义\n准备的重要性 这里说的准备更多是: 五事七计。\n做管理: 考虑编制是如何的，组织架构怎样设计 带团队: 考虑梯队模型时分析成员画像，如五事里的将的能力模型定义：智信仁严勇 做项目: 考虑项目以来的技术，团队，项目本身的ROI等 知己知彼 难在知己 自己能决定失败，对手才能决定能否胜利。\n在势均力敌的时候，对手不犯错一般自己很难胜利。所以说胜利是看对手有没有犯错。对应的，自己的一些准备日常是决定自己能不能失败的。而真的知道自己的实力么，掌握好自己的优缺，了解自己所想要的不？是很关键的也容易被环境带偏\n做决策，客观了么？ 心里学上 人们选择一个事情，不是这个事情真实客观，而是人们期望他是对的，想要他是对的。\n最后生活并没有银弹，养兵千日用兵一时。基本面做的好了，操作面做的再差胜算也大；基本面做的普通，也不要放弃，操作面上还有很多空间。\n尽信书不如无书，理论很多，观点很多，说法很多，怎么去选择，怎么去用呢？\n","permalink":"https://tomorrowthief.github.io/posts/art-of-war/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e近日工作不忙，偶然看到孙子兵法一书，印象里面应是各种打打杀杀，由无他事就读了一些，发现并不是那么简单。\n博主在上下班路上，前后半个月的时间学习了一些。为了加深自己的记忆，理解。就梳理了这篇札记\u003c/p\u003e","title":"孙子兵法-研习记"},{"content":"前言 之前在公司内部做过「扩展性设计」的分享。后面重新整理形成博客形式记录自己的学习。\n由于作者长期从事Web前端领域的工作的原因，本文也是基于这些技术领域发出的一些关于应用软件方向上的扩展性总结\n什么是扩展性设计 软件架构设计里比较关注的几个要素：扩展性，稳定性，可维护性。很多领域里都会有这方面的考虑。比如：业务架构，产品架构，软件技术架构。那么具体怎么定义呢\nExtensibility is a software engineering and systems design principle where the implementation takes future growth into consideration\n扩展性是在考虑未来增长发展时所做的一些工程实践和系统设计原则\n引用自维基百科的定义\n基础理论 这里讨论的理论基础是比较原始的，类似于数学或物理中的定律定理。实践中是要结合具体场景通过组合这里理论，以及基于这些理论做些推导来形成最佳的设计\n找到变化的东西 solid原则 分层明确 常用形式 中间件 中间件是一种实践比较成熟的形式了。基本的思想是根据一些约定拦截输入，做一些逻辑，或者修改挂载上下文，然后继续向下流。具体的形式上有\n洋葱模型中间件： koa2， redux 管道化模型的中间件：pipe 中间件实践中要考虑的因素是：\n中间件收集方式 中间件之间的关系，顺序等 插件 这种形式也比较常见。类似于微内核 + plugin/addon 模型。市面上也存在了很多基于此架构的工具或框架。此模式实践中要考虑的因素是：\n隔离性：暴露主应用的那些能力，防止插件的运行影响主应用逻辑 性能：进程模型设计，是否独立进程运行 生命周期：插件加载时机，插件执行时机 插件之间管理：插件之间是否能互相调用，互相影响 插件机制思想很简单，重要的是各种实现细节，实践中有不同形式与细节。这里日后单独写一篇文章来分析\n配置 读取配置文件，读取参数都是这种形式。是一种简单但实用的形式。不过多讨论\n案例分析 webpack中的扩展性设计 webpack 是一个比较流行的打包工具。其功能的强大，生态的繁荣离不他的插件体系和loader体系。本身作为一个流程控制中心，很多功能都是分散在各个插件里来做的\nloader体系 针对特定的文件类型来做处理的，有点类似上一节提到的管道化中间件模型。针对特定类型文件可以提供多个，按照顺序管道化的处理转换。\n插件体系 webpack 内部主要的两个概念是 complier主要负责构建整体流程等，compliton主要负责构建里的具体编译工作。这两者都是通过 Tapable 库来完成内部生命周期暴露，Tapable 大体上是一种 sub-pub 模式的实现, 其核心概念 hook 可以与 event系统里的某个 event 等价。在同一个hook下可以绑定很多handler的注册，有点像AOP编程思想。\n一个插件的demo\nfunction HelloWorldPlugin(options) { // 使用 options 设置插件实例…… } HelloWorldPlugin.prototype.apply = function(compiler) { compiler.plugin(\u0026#39;done\u0026#39;, function() { console.log(\u0026#39;Hello World!\u0026#39;); }); }; module.exports = HelloWorldPlugin; 解释: 插件是约定实现带有 apply 方法的类(demo中通过构造函数和原型的方式实现)。apply 方法是 webpack 内部使用的。webpack 暴露了 complier 对象给 apply，可以使用其暴露的生命周期钩子来处理所要逻辑，完整的钩子列表可以在官网上找\nbabel 副作用 对，最大的副作用就是过度设计，无论何种设计都不是免费的。完美的扩展机制是需要考虑很多因素的，上文有一些分析。倘若为了尚不明确的问题做复杂的设计，可能得不偿失。\n总结 扩展性很重要，同时也要警惕副作用。切不可为了设计而设计，实用有效，能为公司真正带来价值的才能成为好设计。当然如果职位就是探索研究型的，可以忽略一些副作用\n个人觉得做架构的最佳实践：充分理解问题的场景，规模，特有的属性等，未来的规划，结合基础理论来做具体设计。对未来的增长不明确时，不建议花费很大成本做这些设计。\n","permalink":"https://tomorrowthief.github.io/posts/extend-design/","summary":"\u003ch1 id=\"前言\"\u003e前言\u003c/h1\u003e\n\u003cp\u003e之前在公司内部做过「扩展性设计」的分享。后面重新整理形成博客形式记录自己的学习。\u003c/p\u003e\n\u003cp\u003e由于作者长期从事Web前端领域的工作的原因，本文也是基于这些技术领域发出的一些关于应用软件方向上的扩展性总结\u003c/p\u003e","title":"扩展性设计"},{"content":"深度思考的重要性就不多强调了，该如何做好呢？\n如何做好深度思考？\n多维度 我这里说的多维度可以理解为多视角。\n做一个技术分享，在听众的视角下如何的，主办方的视角如何，分享者的视角又如何，领导视角，同事视角如何……\n多层次 一个事物是处于整体系统里的那一层，与其他层的依赖关系。都是可以考虑的\n比如日常技术问题处理，问题本身是如何的，处理及反馈流程是如何的，技术依赖的其他系统大概如何的……\n现象与本质 有哲学基础的都会知道，事物的发展变化都会有表现与本质的区别。这一点有点像我们使用技术框架时，能掌握好框架的使用层以及底层原理，才能以正确的姿势使用。\n同样道理，思考问题的表现以及底层逻辑如何，才能做好深度思考。实际中可能会更加复杂：人的关系，系统的关系，技术本身的关系\n刻意练习 所谓学而不思则茫，有了理论基础，加上一些刻意练习，才能真正掌握。具体落地点:\n多总结 多复盘 多积累方法论 多接触不同系统的案例 ","permalink":"https://tomorrowthief.github.io/posts/deep-thinking/","summary":"\u003cp\u003e深度思考的重要性就不多强调了，该如何做好呢？\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如何做好深度思考？\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"多维度\"\u003e多维度\u003c/h2\u003e\n\u003cp\u003e我这里说的多维度可以理解为\u003ccode\u003e多视角\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e做一个技术分享，在听众的视角下如何的，主办方的视角如何，分享者的视角又如何，领导视角，同事视角如何……\u003c/p\u003e","title":"深度思考"},{"content":"最近开始学习蛙泳，其实很早之前下水练习过几次，但是没有系统的整理。最近开始了系统性的练习：看了些视频讲解，纠正了些错误，总算有些小进步。\n过程中发现了自己之前很多动作，模式，思考是不对的。但是纠正这些不对的点花费了很久时间。学习效率比较低。而纠正错误的技巧以及思路是一个通用的学习理论，对于工作，生活应该都适用。所以做了此快速学习新技能技巧的总结，或者称之为方法论也好。\n学习速度 掌握好正确的路径，学习资料，其余的就是练习了。理论与实践相辅相承。在实践中遇到问题，可能是理论没有吃透，可以多补充。比如不知道动作该怎么连贯（划手蹬腿结合）的时候，可以补充下理论。理论充足不等于实践也厉害，因为都有个人，环境的因素。\n所以 理论和实践结合 互相补充 来提速\n基础比较关键 最重要的基础点是：\n划手 蹬腿 协调 切记欲速不达的道理： 我之前基础练习的不够好，蹬腿，划手导致在完整动作时漏洞百出，出了问题没有头绪，然后再回过头一点一点练习基础才能做好完整动作，这个过程就比较浪费时间了。 在看专业运动员每一个细节都特别好，大概就是基础比较扎实了吧。所以想要快速达到目标，不要忽视了基础。稳扎稳打可能是速度最快的方式\n好的老师 个人在实践中总是会有很多点会偏离最优，有些思想也会偏离。有的时候会卡在某个环节出不来，这个时候如果自己有良好的资料可以参考，最好了。 比如我在呼气练习的时候，水下一直是哈气的动作，水上就不能很好的吸气了，知道看到有个解说提醒说水下吐气，才知道，这个环节练习错了。这个哈气矫正为吐气的过程是看了讲解。但是假如有个好教师帮忙点一二，可以快速解围解困惑的。\n类似的工作中也比较强调有好的导师，好的领导的重要性，所谓读万卷书不如行万里路，不过阅人无数，不如良师指点。 所以如何发现好老师？正规的学习指南，学习资料是大家当前最合适的，有真人最好了。\n最后发现总结的都是些大道理，这些大道理大家应该都懂，但是怎么与实际结合并帮助实践是比较关键的。\n总结 本文通过个人蛙泳学习过程中遇到的问题做了些反思，总结了一些快速学习技能的通用技巧方法论。并强调这些大道理如何与实际结合的技巧才是关键。希望对做其他事情有帮助，也不枉这次辛苦练习了。最后学习的过程是没有银弹的，前进吧少年\n","permalink":"https://tomorrowthief.github.io/posts/swim/","summary":"\u003cp\u003e最近开始学习蛙泳，其实很早之前下水练习过几次，但是没有系统的整理。最近开始了系统性的练习：看了些视频讲解，纠正了些错误，总算有些小进步。\u003c/p\u003e\n\u003cp\u003e过程中发现了自己之前很多动作，模式，思考是不对的。但是纠正这些不对的点花费了很久时间。学习效率比较低。而纠正错误的技巧以及思路是一个通用的学习理论，对于工作，生活应该都适用。所以做了此快速学习新技能技巧的总结，或者称之为方法论也好。\u003c/p\u003e","title":"蛙泳学思"},{"content":"背景 最近比较空闲，在写作东西的时候发现一个不错的主题。刚好自己除了一些公共账号外，还没自己的博客，遂搭建之。\n主题：基于Hugo，详细可以见网站底部。托管于 GitHub Pages。\n博客内容 主要是搬移之前写过的一些东西，同时做了一些格式化处理。未来新写的东西应该会首先发到这里了\n菩提本无树，明镜亦非台，本来无一物，何处惹尘埃\n","permalink":"https://tomorrowthief.github.io/posts/kaishila/","summary":"\u003ch1 id=\"背景\"\u003e背景\u003c/h1\u003e\n\u003cp\u003e最近比较空闲，在写作东西的时候发现一个不错的主题。刚好自己除了一些公共账号外，还没自己的博客，遂搭建之。\u003c/p\u003e\n\u003cp\u003e主题：基于Hugo，详细可以见网站底部。托管于 \u003ccode\u003eGitHub Pages\u003c/code\u003e。\u003c/p\u003e","title":"文章搬运开始啦"},{"content":"Web 开发，软件开发，架构师，生活探索者。混迹于 杭州 / 郑州。\n技能 \u0026amp; 语言\nFront End，Nodejs, Python, Golang AI Application, LLM, Agentic Application 近期在学\nSomething about Web3 Neurons Networks \u0026amp; Transformer ","permalink":"https://tomorrowthief.github.io/about/","summary":"about","title":"About"}]