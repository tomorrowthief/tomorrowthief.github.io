---
title: "LLM 长记忆工具总结"
date: 2024-10-22T10:48:00+08:00
draft: false
---

# 背景
近期工作中做了个 LLM 长记忆功能，对此中的思路，技术做下总结

## 功能及分析
简单来说就是让大模型具备记忆功能，记住某个人。其实就是为了打造一个长期个人助手。不同于某次会话上下文记忆，长记忆具备的特点：

1. 跟随个人的：我们目前常见的短期记忆只是跟随某次会话
2. 时间长：1年，5年，10年，…… 终生
3. 个人信息相关的：比如个人爱好，心情变化，健康，工作，生活等这些属于个人记忆，还有一些客观信息事实信息，比如：美国在北美洲，地球是圆的。这些不需要作为记忆信息。







会话信息里怎么识别出哪些是可以作为记忆的？哪些是客体信息，不作为记忆，来减少

## 方案及问题
总体还是 RAG 的思路上进行优化。需要考虑的一些点
1. 存储哪些信息？所有会话信息？用户输入问题？llm回答？
2. 怎么确定哪些是需要纳入记忆里的信息，比如个人爱好，基本信息，肯定是记忆。而有一些：客观信息：比如地球是圆的，美国在北美洲。这些不需要作为记忆存储
3. 日程相关的怎么做？


## 方案实现
实现一个记忆引擎来完成总体记忆的管理，记忆引擎内部完成记忆的提取，增删改，记忆的召回

### 流程交互图





### 知识图谱引进
知识图谱引进主要是为了解决：向量检索带来的信息相关度较小，


### 用大模型自己去解决大模型的问题


## 社区方案

1. [mem0](https://github.com/mem0ai/mem0)

我在实践过程中严重依赖了这个方案，不得不说社区力量还是强大



# 总结
在实际中体验下来，最终方案已经基本能用。提交给产品后，收获到了一些正向反馈。

方案上还是会演进的，因为目前总体上还是提示词工程的玩法。这种模式会受到大模型本身技术发展影响的
